"""
Teste Unit√°rio Completo - Sistema de An√°lise de Editais
Testa o pipeline LangNet com documentos reais de editais usando DeepSeek
"""
import sys
import os
import time
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from agents.langnetagents import execute_document_analysis_workflow
from agents.langnetstate import LangNetFullState, init_full_state
from services.memory_service import AgentMemoryService
from utils.pdf_processor import process_pdf_for_agent


# ============================================================================
# CONFIGURA√á√ÉO DO TESTE
# ============================================================================

EDITAIS_DIR = "/home/pasteurjr/progreact/langnet-interface/instancias/editais"
TEST_PROJECT_ID = "test-editais-001"
TEST_PROJECT_NAME = "Sistema de Sele√ß√£o e An√°lise de Editais"

# Instru√ß√µes detalhadas sobre o sistema
SYSTEM_INSTRUCTIONS = """
PROPOSTA DE ARQUITETURA DO SISTEMA DE IA PARA LICITA√á√ïES:

1. Cadastro Inteligente do Portf√≥lio:
   - Cria√ß√£o de uma m√°scara de entrada totalmente parametriz√°vel
   - A empresa informa as caracter√≠sticas t√©cnicas dos produtos por classe, seguindo os crit√©rios normalmente avaliados nos certames
   - A IA tamb√©m realiza a leitura dos manuais t√©cnicos e sugere novos campos ou requisitos faltantes para enriquecer o cadastro

2. Agente de IA para Captura e Leitura dos Certames:
   - Um agente aut√¥nomo monitora diariamente as fontes p√∫blicas (federal, estaduais e municipais) e captura novos editais
   - O sistema l√™ o edital, interpreta cl√°usulas t√©cnicas e administrativas e calcula automaticamente o grau de ader√™ncia de cada item aos produtos cadastrados

3. Sugest√£o de Participa√ß√£o:
   - Com base na an√°lise do edital, a IA identifica quais produtos da empresa s√£o aderentes e recomenda a participa√ß√£o
   - O agente tamb√©m lista os requisitos t√©cnicos, administrativos e documentais que precisam compor a proposta e os anexos obrigat√≥rios

4. Gera√ß√£o Autom√°tica da Proposta:
   - A IA monta automaticamente a proposta completa:
     * texto t√©cnico aderente ao edital
     * documentos oficiais e complementares
     * fichas t√©cnicas e anexos
     * arquivo final organizado para envio eletr√¥nico ou impress√£o (para licita√ß√µes presenciais)
   - Um painel de revis√£o permite ajustes antes do envio

CONTEXTO DO SISTEMA:

Voc√™ est√° analisando documentos para criar um Sistema Inteligente de Sele√ß√£o e An√°lise de Editais de Licita√ß√£o.

OBJETIVOS DO SISTEMA:
1. **Capta√ß√£o Autom√°tica de Editais**: Monitorar portais p√∫blicos (ComprasNet, Licita√ß√µes-e, portais estaduais/municipais)
   para identificar novos editais relevantes para a empresa.

2. **An√°lise Inteligente**: Extrair informa√ß√µes cr√≠ticas dos editais:
   - Tipo de licita√ß√£o (Preg√£o Eletr√¥nico, Concorr√™ncia, Tomada de Pre√ßos, etc.)
   - Objeto da licita√ß√£o (descri√ß√£o do que est√° sendo contratado)
   - Valor estimado e limites or√ßament√°rios
   - Prazo de entrega/execu√ß√£o
   - Documenta√ß√£o de habilita√ß√£o exigida
   - Crit√©rios de julgamento (menor pre√ßo, melhor t√©cnica, t√©cnica e pre√ßo)
   - Exig√™ncias t√©cnicas espec√≠ficas
   - Garantias e seguros necess√°rios
   - Prazos cr√≠ticos (entrega de propostas, sess√£o p√∫blica)

3. **Classifica√ß√£o de Viabilidade**: Avaliar automaticamente se a empresa tem condi√ß√µes de participar:
   - Capacidade t√©cnica (hist√≥rico, atestados)
   - Capacidade financeira (balan√ßos, capital social)
   - Conformidade documental (certid√µes, registros)
   - Adequa√ß√£o ao objeto (produtos/servi√ßos oferecidos)
   - Prazo realista de prepara√ß√£o da proposta

4. **Gest√£o de Requisitos**: Extrair e estruturar requisitos:
   - Requisitos funcionais (o que o sistema deve fazer)
   - Requisitos n√£o-funcionais (performance, seguran√ßa, disponibilidade)
   - Regras de neg√≥cio (Lei 14.133/2021, decretos, instru√ß√µes normativas)
   - Conformidade legal (LGPD, acessibilidade, transpar√™ncia)

5. **Alertas e Notifica√ß√µes**: Sistema de alerta para:
   - Editais que atendem ao perfil da empresa
   - Prazos se aproximando
   - Mudan√ßas em editais monitorados
   - Resultados de licita√ß√µes participadas

6. **An√°lise de Concorr√™ncia**: Identificar:
   - Empresas que costumam participar
   - Padr√µes de pre√ßos vencedores
   - Taxa de sucesso por tipo de licita√ß√£o

INFORMA√á√ïES IMPORTANTES A EXTRAIR DOS DOCUMENTOS:

1. **Processos de Licita√ß√£o**:
   - Etapas do processo licitat√≥rio (da publica√ß√£o ao contrato)
   - Documentos obrigat√≥rios em cada fase
   - Prazos legais e procedimentais
   - Recursos e impugna√ß√µes

2. **Crit√©rios de Habilita√ß√£o**:
   - Habilita√ß√£o jur√≠dica (CNPJ, contrato social, inscri√ß√µes)
   - Regularidade fiscal (federal, estadual, municipal, trabalhista)
   - Qualifica√ß√£o t√©cnica (atestados, certid√µes, registros profissionais)
   - Qualifica√ß√£o econ√¥mico-financeira (balan√ßos, √≠ndices)
   - Garantias de proposta e execu√ß√£o

3. **Nova Lei de Licita√ß√µes (Lei 14.133/2021)**:
   - Mudan√ßas em rela√ß√£o √† Lei 8.666/93
   - Novos procedimentos e modalidades
   - Uso obrigat√≥rio de meios eletr√¥nicos
   - Portal Nacional de Contrata√ß√µes P√∫blicas (PNCP)

4. **Boas Pr√°ticas**:
   - An√°lise estrat√©gica de editais
   - Montagem de propostas vencedoras
   - Gest√£o de prazos e documenta√ß√£o
   - Evitar erros comuns (inabilita√ß√£o, desclassifica√ß√£o)

5. **Planilhas de Custos**:
   - Estrutura de composi√ß√£o de pre√ßos
   - Custos diretos e indiretos
   - BDI (Bonifica√ß√£o e Despesas Indiretas)
   - Encargos sociais e trabalhistas

REQUISITOS T√âCNICOS ESPERADOS:

- **Backend**: API REST, processamento ass√≠ncrono, web scraping, NLP
- **Banco de Dados**: Armazenamento de editais, empresas, propostas, hist√≥rico
- **Machine Learning**: Classifica√ß√£o de editais, extra√ß√£o de entidades, pontua√ß√£o de viabilidade
- **Integra√ß√µes**: Portais de licita√ß√£o, Receita Federal (CNPJs), Serasa (certid√µes)
- **Frontend**: Dashboard, alertas, visualiza√ß√£o de editais, gera√ß√£o de relat√≥rios
- **Seguran√ßa**: Autentica√ß√£o, criptografia, auditoria, LGPD

COMPLEMENTA√á√ÉO COM WEB RESEARCH:

Por favor, busque na web informa√ß√µes sobre:
1. Melhores pr√°ticas em an√°lise de editais de licita√ß√£o (2024)
2. Principais portais de licita√ß√£o no Brasil
3. Ferramentas de automa√ß√£o para licita√ß√µes
4. API do Portal Nacional de Contrata√ß√µes P√∫blicas (PNCP)
5. Requisitos da Lei 14.133/2021 (Nova Lei de Licita√ß√µes)
6. Tecnologias de NLP para extra√ß√£o de informa√ß√µes de editais
7. Conformidade com LGPD em sistemas de licita√ß√µes
8. Integra√ß√µes com sistemas governamentais (Serpro, Receita Federal)
"""


# ============================================================================
# FUN√á√ïES AUXILIARES
# ============================================================================

def get_pdf_files():
    """Lista todos os PDFs na pasta de editais"""
    pdf_files = list(Path(EDITAIS_DIR).glob("*.pdf"))
    return sorted(pdf_files)


def parse_nested_json(data, key_path="team_result"):
    """
    Parse JSON that may be wrapped in team_result and/or markdown code fences.
    Handles formats like:
    1. '{"team_result": "..."}'
    2. '{"team_result": "```json\n{...}\n```"}'
    3. Direct JSON objects
    """
    if not data:
        return {}

    # If already a dict, return as-is
    if isinstance(data, dict):
        # Check if it has team_result key
        if "team_result" in data:
            data = data["team_result"]
        else:
            return data

    # If string, try to parse
    if isinstance(data, str):
        try:
            # First parse: get outer JSON
            parsed = json.loads(data)

            # Extract team_result if present
            if isinstance(parsed, dict) and "team_result" in parsed:
                inner_str = parsed["team_result"]

                # Remove markdown code fence if present
                if isinstance(inner_str, str):
                    inner_str = inner_str.strip()
                    if inner_str.startswith("```json"):
                        inner_str = inner_str[7:]  # Remove ```json
                    if inner_str.startswith("```"):
                        inner_str = inner_str[3:]  # Remove ```
                    if inner_str.endswith("```"):
                        inner_str = inner_str[:-3]  # Remove trailing ```
                    inner_str = inner_str.strip()

                    # Second parse: get actual data
                    try:
                        return json.loads(inner_str)
                    except:
                        return {}
                return inner_str if isinstance(inner_str, dict) else {}
            return parsed
        except Exception as e:
            print(f"   ‚ö†Ô∏è  JSON parse error: {str(e)[:100]}")
            return {}

    return {}


def format_duration(seconds):
    """Formata dura√ß√£o em minutos e segundos"""
    mins = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{mins}m {secs}s"


def save_result(result_data, output_file):
    """Salva resultado em arquivo JSON"""
    output_path = Path(__file__).parent / "results" / output_file
    output_path.parent.mkdir(exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)

    return output_path


def save_requirements_document(markdown_content, output_file):
    """Salva documento de requisitos em MD"""
    output_path = Path(__file__).parent / "results" / output_file
    output_path.parent.mkdir(exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(markdown_content)

    return output_path


# ============================================================================
# TESTES UNIT√ÅRIOS
# ============================================================================

def test_single_document(pdf_path: Path, use_deepseek: bool = True):
    """
    Testa an√°lise de um √∫nico documento

    Args:
        pdf_path: Caminho para o PDF
        use_deepseek: Se True, usa DeepSeek; se False, usa OpenAI

    Returns:
        dict com resultados do teste
    """
    print(f"\n{'='*80}")
    print(f"TESTE: {pdf_path.name}")
    print(f"LLM: {'DeepSeek' if use_deepseek else 'OpenAI GPT-4'}")
    print(f"{'='*80}\n")

    test_result = {
        "document_name": pdf_path.name,
        "document_path": str(pdf_path),
        "document_size_mb": round(pdf_path.stat().st_size / (1024 * 1024), 2),
        "llm_provider": "deepseek" if use_deepseek else "openai",
        "start_time": datetime.now().isoformat(),
        "end_time": None,
        "duration_seconds": 0,
        "status": "running",
        "errors": [],
        "warnings": [],
        "metrics": {},
        "state": None
    }

    start_time = time.time()

    try:
        # Criar document_id √∫nico
        document_id = f"doc-{pdf_path.stem.replace(' ', '-')[:30]}-{int(time.time())}"

        print(f"üìÑ Documento: {pdf_path.name} ({test_result['document_size_mb']} MB)")
        print(f"üÜî Document ID: {document_id}")
        print(f"‚è±Ô∏è  In√≠cio: {test_result['start_time']}")

        # ==================== NOVO: Processar PDF com chunking ====================
        print(f"\nüîß Processando PDF (extra√ß√£o + chunking)...\n")
        pdf_processed = process_pdf_for_agent(
            str(pdf_path),
            max_pages=50,
            chunk_size=1000,
            chunk_overlap=200,
            max_chunks=60
        )

        # Juntar todos os chunks formatados em um √∫nico texto
        document_content_chunked = "\n\n".join(pdf_processed['formatted_chunks'])

        print(f"‚úÖ PDF processado:")
        print(f"   üìù Texto extra√≠do: {pdf_processed['stats']['raw_text_length']:,} chars ({pdf_processed['stats']['raw_text_words']:,} palavras)")
        print(f"   ‚úÇÔ∏è  Chunks gerados: {pdf_processed['stats']['num_formatted_chunks']}")
        print(f"   üì¶ Tamanho m√©dio do chunk: {pdf_processed['stats']['avg_chunk_size']:.0f} chars")
        print(f"\nüîÑ Iniciando workflow de an√°lise...\n")
        # ==========================================================================

        # Executar workflow de an√°lise COM TEXTO CHUNKADO
        result_state = execute_document_analysis_workflow(
            project_id=TEST_PROJECT_ID,
            document_id=document_id,
            document_path=str(pdf_path),
            document_content=document_content_chunked,  # NOVO: passar texto chunkado
            project_name=TEST_PROJECT_NAME,
            project_description="Sistema inteligente para capta√ß√£o, an√°lise e gest√£o de editais de licita√ß√£o p√∫blica",
            project_domain="Licita√ß√µes e Contrata√ß√µes P√∫blicas",
            additional_instructions=SYSTEM_INSTRUCTIONS,
            document_type="pdf",
            use_deepseek=use_deepseek
        )

        end_time = time.time()
        duration = end_time - start_time

        test_result["end_time"] = datetime.now().isoformat()
        test_result["duration_seconds"] = round(duration, 2)
        test_result["status"] = "completed"
        test_result["state"] = result_state

        # Extrair m√©tricas
        # Parse requirements and research data with proper nested parsing
        requirements_data = parse_nested_json(result_state.get("requirements_json", "{}"))
        research_data = parse_nested_json(result_state.get("research_findings", "{}"))

        test_result["metrics"] = {
            "completed_tasks": result_state.get("completed_tasks", 0),
            "total_tasks": result_state.get("total_tasks", 0),
            "progress_percentage": result_state.get("progress_percentage", 0),
            "requirements_count": len(requirements_data.get("functional_requirements", [])),
            "nfr_count": len(requirements_data.get("non_functional_requirements", [])),
            "business_rules_count": len(requirements_data.get("business_rules", [])),
            "entities_count": len(requirements_data.get("entities", [])),
            "actors_count": len(requirements_data.get("actors", [])),
            "web_research_queries": len(research_data.get("queries", [])),
            "web_research_results": len(research_data.get("results", [])),
            "document_word_count": len(result_state.get("document_content", "").split()),
            "requirements_doc_length": len(result_state.get("requirements_document_md", ""))
        }

        # Verificar e reportar erros
        if result_state.get("errors"):
            print(f"\n‚ö†Ô∏è  ERROS DETECTADOS DURANTE EXECU√á√ÉO: {len(result_state['errors'])}")
            for err in result_state["errors"]:
                print(f"   ‚ùå Task: {err.get('task', 'unknown')}")
                print(f"      Erro: {err.get('error_message', 'no message')[:200]}")
            test_result["warnings"].extend(result_state["errors"])

        # Verificar se requisitos foram extra√≠dos
        if test_result["metrics"]["requirements_count"] == 0:
            print(f"\n‚ö†Ô∏è  ATEN√á√ÉO: Nenhum requisito funcional extra√≠do!")
            if not result_state.get("errors"):
                print(f"   Poss√≠vel causa: LLM n√£o retornou JSON no formato esperado")
                print(f"   Verificar output do task 'extract_requirements'")

        # Original warnings check
        if result_state.get("errors"):
            pass  # Already handled above

        # Salvar documento de requisitos
        if result_state.get("requirements_document_md"):
            doc_filename = f"{pdf_path.stem}_requirements.md"
            doc_path = save_requirements_document(
                result_state["requirements_document_md"],
                doc_filename
            )
            test_result["requirements_document_path"] = str(doc_path)
            print(f"\n‚úÖ Documento de requisitos salvo: {doc_path}")

        print(f"\n{'='*80}")
        print(f"‚úÖ TESTE CONCLU√çDO COM SUCESSO")
        print(f"‚è±Ô∏è  Dura√ß√£o: {format_duration(duration)}")
        print(f"üìä Requisitos Funcionais: {test_result['metrics']['requirements_count']}")
        print(f"üìä Requisitos N√£o-Funcionais: {test_result['metrics']['nfr_count']}")
        print(f"üìä Regras de Neg√≥cio: {test_result['metrics']['business_rules_count']}")
        print(f"üìä Entidades: {test_result['metrics']['entities_count']}")
        print(f"üìä Atores: {test_result['metrics']['actors_count']}")
        print(f"üåê Queries Web Research: {test_result['metrics']['web_research_queries']}")
        print(f"üåê Resultados Web Research: {test_result['metrics']['web_research_results']}")
        print(f"{'='*80}\n")

    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time

        test_result["end_time"] = datetime.now().isoformat()
        test_result["duration_seconds"] = round(duration, 2)
        test_result["status"] = "failed"
        test_result["errors"].append({
            "type": type(e).__name__,
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        })

        print(f"\n{'='*80}")
        print(f"‚ùå TESTE FALHOU")
        print(f"‚è±Ô∏è  Dura√ß√£o at√© falha: {format_duration(duration)}")
        print(f"‚ùå Erro: {type(e).__name__}: {str(e)}")
        print(f"{'='*80}\n")

    return test_result


def test_multiple_documents(pdf_paths: list, use_deepseek: bool = True, limit: int = None):
    """
    Testa an√°lise de m√∫ltiplos documentos

    Args:
        pdf_paths: Lista de caminhos para PDFs
        use_deepseek: Se True, usa DeepSeek
        limit: Limite de documentos a testar (None = todos)

    Returns:
        dict com resultados agregados
    """
    if limit:
        pdf_paths = pdf_paths[:limit]

    print(f"\n{'='*80}")
    print(f"TESTE EM LOTE: {len(pdf_paths)} documentos")
    print(f"LLM: {'DeepSeek' if use_deepseek else 'OpenAI GPT-4'}")
    print(f"{'='*80}\n")

    batch_result = {
        "test_suite": "editais_batch_test",
        "total_documents": len(pdf_paths),
        "llm_provider": "deepseek" if use_deepseek else "openai",
        "start_time": datetime.now().isoformat(),
        "end_time": None,
        "total_duration_seconds": 0,
        "tests": [],
        "summary": {
            "completed": 0,
            "failed": 0,
            "total_requirements": 0,
            "total_nfr": 0,
            "total_business_rules": 0,
            "total_entities": 0,
            "total_web_queries": 0,
            "avg_duration_seconds": 0
        }
    }

    batch_start = time.time()

    for i, pdf_path in enumerate(pdf_paths, 1):
        print(f"\nüìÑ Testando {i}/{len(pdf_paths)}: {pdf_path.name}")

        test_result = test_single_document(pdf_path, use_deepseek)
        batch_result["tests"].append(test_result)

        # Atualizar summary
        if test_result["status"] == "completed":
            batch_result["summary"]["completed"] += 1
            batch_result["summary"]["total_requirements"] += test_result["metrics"].get("requirements_count", 0)
            batch_result["summary"]["total_nfr"] += test_result["metrics"].get("nfr_count", 0)
            batch_result["summary"]["total_business_rules"] += test_result["metrics"].get("business_rules_count", 0)
            batch_result["summary"]["total_entities"] += test_result["metrics"].get("entities_count", 0)
            batch_result["summary"]["total_web_queries"] += test_result["metrics"].get("web_research_queries", 0)
        else:
            batch_result["summary"]["failed"] += 1

        # Pausa entre testes (rate limiting)
        if i < len(pdf_paths):
            print(f"\n‚è≥ Aguardando 5 segundos antes do pr√≥ximo teste...\n")
            time.sleep(5)

    batch_end = time.time()
    batch_duration = batch_end - batch_start

    batch_result["end_time"] = datetime.now().isoformat()
    batch_result["total_duration_seconds"] = round(batch_duration, 2)

    if batch_result["summary"]["completed"] > 0:
        total_duration_completed = sum(
            t["duration_seconds"] for t in batch_result["tests"]
            if t["status"] == "completed"
        )
        batch_result["summary"]["avg_duration_seconds"] = round(
            total_duration_completed / batch_result["summary"]["completed"], 2
        )

    return batch_result


def test_multiple_documents_consolidated(pdf_paths: list, use_deepseek: bool = False):
    """
    Testa an√°lise de m√∫ltiplos documentos CONSOLIDADOS (1 execu√ß√£o do agent)

    Esta fun√ß√£o processa todos os PDFs de uma vez, gerando um √∫nico documento
    de requisitos consolidado. √â MUITO mais r√°pido que processar individualmente.

    Args:
        pdf_paths: Lista de caminhos para PDFs
        use_deepseek: Se True, usa DeepSeek; se False, usa OpenAI GPT-4

    Returns:
        LangNetFullState com documento consolidado
    """
    print(f"\n{'='*80}")
    print(f"TESTE CONSOLIDADO: {len(pdf_paths)} documentos em 1 execu√ß√£o")
    print(f"LLM: {'DeepSeek' if use_deepseek else 'OpenAI GPT-4'}")
    print(f"{'='*80}\n")

    # Listar documentos
    print(f"üìã Documentos a processar:")
    for i, pdf_path in enumerate(pdf_paths, 1):
        size_mb = round(pdf_path.stat().st_size / (1024 * 1024), 2)
        print(f"   {i}. {pdf_path.name} ({size_mb} MB)")

    print(f"\n‚è≥ Processando PDFs e consolidando conte√∫do...")

    # Processar todos os PDFs e juntar conte√∫do
    all_content_parts = []
    total_size_mb = 0

    for pdf_path in pdf_paths:
        size_mb = pdf_path.stat().st_size / (1024 * 1024)
        total_size_mb += size_mb

        print(f"   üìÑ Processando: {pdf_path.name}...")
        content = process_pdf_for_agent(str(pdf_path))

        # Adicionar separador claro entre documentos
        all_content_parts.append(f"""
{'='*80}
DOCUMENTO: {pdf_path.name}
TAMANHO: {size_mb:.2f} MB
{'='*80}

{content}
""")

    # Juntar todo o conte√∫do
    consolidated_content = "\n\n".join(all_content_parts)

    print(f"\n‚úÖ {len(pdf_paths)} documentos processados ({total_size_mb:.2f} MB total)")
    print(f"üìä Tamanho consolidado: {len(consolidated_content)} caracteres")
    print(f"\nü§ñ Executando an√°lise consolidada com agent...")
    print(f"‚ö†Ô∏è  ATEN√á√ÉO: Processamento pode levar 5-15 minutos\n")

    start_time = time.time()

    try:
        # Executar UMA VEZ com todo o conte√∫do consolidado
        result_state = execute_document_analysis_workflow(
            project_id=TEST_PROJECT_ID,
            document_id=f"consolidated_{len(pdf_paths)}_docs_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            document_path=str(pdf_paths[0]),  # Path do primeiro como refer√™ncia
            project_name=TEST_PROJECT_NAME,
            project_description=f"An√°lise consolidada de {len(pdf_paths)} documentos sobre editais de licita√ß√£o",
            additional_instructions=SYSTEM_INSTRUCTIONS,
            use_deepseek=use_deepseek,
            document_content=consolidated_content,  # TODOS OS DOCUMENTOS JUNTOS
            enable_web_research=True  # HABILITADO: Pesquisa web para enriquecer requisitos
        )

        end_time = time.time()
        duration = end_time - start_time

        print(f"\n{'='*80}")
        print(f"‚úÖ AN√ÅLISE CONSOLIDADA CONCLU√çDA")
        print(f"‚è±Ô∏è  Dura√ß√£o: {format_duration(duration)}")
        print(f"{'='*80}\n")

        # Extrair m√©tricas
        requirements_json = result_state.get("requirements_json", "{}")
        requirements_data = parse_nested_json(requirements_json)

        functional_reqs = requirements_data.get("functional_requirements", [])
        nonfunctional_reqs = requirements_data.get("non_functional_requirements", [])
        business_rules = requirements_data.get("business_rules", [])
        entities = requirements_data.get("entities", [])
        actors = requirements_data.get("actors", [])

        print(f"üìä M√âTRICAS CONSOLIDADAS:")
        print(f"   Requisitos Funcionais: {len(functional_reqs)}")
        print(f"   Requisitos N√£o-Funcionais: {len(nonfunctional_reqs)}")
        print(f"   Regras de Neg√≥cio: {len(business_rules)}")
        print(f"   Entidades: {len(entities)}")
        print(f"   Atores: {len(actors)}")
        print(f"\n")

        # Salvar documento consolidado
        md_path = Path(__file__).parent / "results" / "documento_requisitos_extraido.md"
        md_path.parent.mkdir(exist_ok=True)

        requirements_md = result_state.get("requirements_document_md", "")

        if requirements_md:
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(requirements_md)
            print(f"üìù Documento consolidado salvo: {md_path}")
            print(f"   Tamanho: {len(requirements_md)} caracteres\n")
        else:
            print(f"‚ö†Ô∏è  AVISO: Documento de requisitos vazio!\n")

        # Salvar JSON completo para debug
        json_path = Path(__file__).parent / "results" / f"consolidated_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        save_result(result_state, json_path.name)
        print(f"üíæ Estado completo salvo: {json_path}\n")

        return result_state

    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time

        print(f"\n{'='*80}")
        print(f"‚ùå ERRO NA AN√ÅLISE CONSOLIDADA")
        print(f"‚è±Ô∏è  Dura√ß√£o at√© falha: {format_duration(duration)}")
        print(f"‚ùå Erro: {type(e).__name__}: {str(e)}")
        print(f"{'='*80}\n")

        raise


def generate_report(batch_result: dict):
    """Gera relat√≥rio formatado dos testes"""

    report = f"""
{'='*80}
RELAT√ìRIO DE TESTES - SISTEMA DE AN√ÅLISE DE EDITAIS
{'='*80}

üìÖ Data: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
ü§ñ LLM Provider: {batch_result['llm_provider'].upper()}
üìÑ Documentos Testados: {batch_result['total_documents']}
‚è±Ô∏è  Dura√ß√£o Total: {format_duration(batch_result['total_duration_seconds'])}

{'='*80}
RESUMO GERAL
{'='*80}

‚úÖ Testes Conclu√≠dos: {batch_result['summary']['completed']} ({batch_result['summary']['completed']/batch_result['total_documents']*100:.1f}%)
‚ùå Testes Falhados: {batch_result['summary']['failed']} ({batch_result['summary']['failed']/batch_result['total_documents']*100:.1f}%)
‚è±Ô∏è  Dura√ß√£o M√©dia: {format_duration(batch_result['summary']['avg_duration_seconds'])}

{'='*80}
M√âTRICAS AGREGADAS
{'='*80}

üìä Total de Requisitos Funcionais: {batch_result['summary']['total_requirements']}
üìä Total de Requisitos N√£o-Funcionais: {batch_result['summary']['total_nfr']}
üìä Total de Regras de Neg√≥cio: {batch_result['summary']['total_business_rules']}
üìä Total de Entidades Identificadas: {batch_result['summary']['total_entities']}
üåê Total de Queries Web Research: {batch_result['summary']['total_web_queries']}

{'='*80}
RESULTADOS POR DOCUMENTO
{'='*80}

"""

    for i, test in enumerate(batch_result['tests'], 1):
        status_icon = "‚úÖ" if test['status'] == 'completed' else "‚ùå"

        report += f"""
{i}. {status_icon} {test['document_name']}
   Tamanho: {test['document_size_mb']} MB
   Status: {test['status'].upper()}
   Dura√ß√£o: {format_duration(test['duration_seconds'])}
"""

        if test['status'] == 'completed':
            metrics = test['metrics']
            report += f"""   Requisitos Funcionais: {metrics.get('requirements_count', 0)}
   Requisitos N√£o-Funcionais: {metrics.get('nfr_count', 0)}
   Regras de Neg√≥cio: {metrics.get('business_rules_count', 0)}
   Entidades: {metrics.get('entities_count', 0)}
   Atores: {metrics.get('actors_count', 0)}
   Web Research Queries: {metrics.get('web_research_queries', 0)}
   Web Research Results: {metrics.get('web_research_results', 0)}
   Palavras no Documento: {metrics.get('document_word_count', 0):,}
   Tamanho Doc. Requisitos: {metrics.get('requirements_doc_length', 0):,} chars
"""
            if test.get('requirements_document_path'):
                report += f"   üìÑ Documento Requisitos: {test['requirements_document_path']}\n"
        else:
            if test.get('errors'):
                for error in test['errors']:
                    report += f"   ‚ùå Erro: {error['type']}: {error['message']}\n"

        report += "\n"

    report += f"""
{'='*80}
AN√ÅLISE DE DESEMPENHO
{'='*80}

Tempo m√©dio por documento: {format_duration(batch_result['summary']['avg_duration_seconds'])}
Requisitos funcionais por documento: {batch_result['summary']['total_requirements']/max(batch_result['summary']['completed'], 1):.1f}
Requisitos n√£o-funcionais por documento: {batch_result['summary']['total_nfr']/max(batch_result['summary']['completed'], 1):.1f}
Regras de neg√≥cio por documento: {batch_result['summary']['total_business_rules']/max(batch_result['summary']['completed'], 1):.1f}
Entidades por documento: {batch_result['summary']['total_entities']/max(batch_result['summary']['completed'], 1):.1f}
Queries web research por documento: {batch_result['summary']['total_web_queries']/max(batch_result['summary']['completed'], 1):.1f}

{'='*80}
CONCLUS√ÉO
{'='*80}

Taxa de Sucesso: {batch_result['summary']['completed']/batch_result['total_documents']*100:.1f}%
Qualidade: {"EXCELENTE ‚úÖ" if batch_result['summary']['completed']/batch_result['total_documents'] > 0.9 else "BOA ‚úÖ" if batch_result['summary']['completed']/batch_result['total_documents'] > 0.7 else "REGULAR ‚ö†Ô∏è" if batch_result['summary']['completed']/batch_result['total_documents'] > 0.5 else "BAIXA ‚ùå"}
Performance: {"EXCELENTE ‚úÖ" if batch_result['summary']['avg_duration_seconds'] < 180 else "BOA ‚úÖ" if batch_result['summary']['avg_duration_seconds'] < 300 else "REGULAR ‚ö†Ô∏è" if batch_result['summary']['avg_duration_seconds'] < 420 else "BAIXA ‚ùå"}

{'='*80}
FIM DO RELAT√ìRIO
{'='*80}
"""

    return report


# ============================================================================
# MAIN
# ============================================================================

def main():
    """Executa su√≠te de testes"""

    print(f"\n{'='*80}")
    print("SU√çTE DE TESTES - SISTEMA DE AN√ÅLISE DE EDITAIS")
    print(f"{'='*80}\n")

    # Listar PDFs dispon√≠veis
    pdf_files = get_pdf_files()

    print(f"üìÇ Pasta de editais: {EDITAIS_DIR}")
    print(f"üìÑ PDFs encontrados: {len(pdf_files)}")
    print(f"\nüìã Lista de documentos:")
    for i, pdf in enumerate(pdf_files, 1):
        size_mb = round(pdf.stat().st_size / (1024 * 1024), 2)
        print(f"   {i}. {pdf.name} ({size_mb} MB)")

    # Selecionar 2 documentos para teste consolidado (mais relevantes para o contexto de sistema de IA para licita√ß√µes)
    selected_names = [
        "An√°lise estrat√©gica de edital passo a passo - eLicita√ß√£o.pdf",  # An√°lise e leitura de editais
        "Manual de Licitacoes para Micro e Pequenas Empresas.pdf"  # Manual completo sobre licita√ß√µes
    ]
    test_pdfs = [pdf for pdf in pdf_files if pdf.name in selected_names]

    if len(test_pdfs) < 2:
        print(f"\n‚ö†Ô∏è  AVISO: Apenas {len(test_pdfs)} dos 2 documentos selecionados foram encontrados")
        if len(test_pdfs) == 0:
            print(f"‚ùå ERRO: Nenhum documento encontrado!")
            return

    print(f"\nüß™ Testando {len(test_pdfs)} documento(s) CONSOLIDADO(S) com GPT-4o-mini...")
    print(f"\n‚ö†Ô∏è  NOTA: An√°lise consolidada pode levar 5-15 minutos (mais r√°pido que individual!)\n")

    # Confirmar antes de continuar
    import sys
    if "--yes" in sys.argv or "-y" in sys.argv:
        print("\n‚ñ∂Ô∏è  Executando testes automaticamente...")
    else:
        try:
            response = input("Deseja continuar? (s/n): ")
            if response.lower() != 's':
                print("\n‚ùå Teste cancelado pelo usu√°rio")
                return
        except EOFError:
            print("\n‚ñ∂Ô∏è  Input n√£o dispon√≠vel, executando automaticamente...")
            pass

    # Executar teste CONSOLIDADO (1 execu√ß√£o para todos os documentos)
    result_state = test_multiple_documents_consolidated(test_pdfs, use_deepseek=False)

    print(f"\n{'='*80}")
    print(f"‚úÖ TESTE CONSOLIDADO FINALIZADO")
    print(f"üìù Documento de requisitos salvo em:")
    print(f"   tests/results/documento_requisitos_extraido.md")
    print(f"{'='*80}\n")

    return result_state


if __name__ == "__main__":
    main()
