# LangNet Tasks Configuration
# Based on CrewAI task definition format

# Document Analysis Tasks
analyze_document:
  description: >
    [Document Analysis] Extract ALL information from provided DOCUMENTS and INSTRUCTIONS.

    YOU RECEIVE 2 INPUT SOURCES:

    SOURCE 1 - DOCUMENTS (PRIMARY):
    - document_content: {document_content}
      This contains FULL TEXT extracted from uploaded files (PDFs, DOCX, etc.)
      May be divided into CHUNKS if long (separated by "---CHUNK---")
      This is the PRIMARY source of FACTUAL information about current state

    SOURCE 2 - INSTRUCTIONS (CONTEXT):
    - additional_instructions: {additional_instructions}
      This contains objectives, goals, context provided by the user
      This provides INTENT and PURPOSE for the system being built
      This is SECONDARY but important for understanding desired state

    CRITICAL:
    - document_content is ALREADY EXTRACTED - work directly with the text provided
    - DO NOT try to read files or use document_reader tool
    - Process ALL chunks if present (they are parts of same logical document)

    YOUR TASK: Analyze BOTH sources to understand the complete picture.

    STEP 1 - READ BOTH SOURCES:

    (A) Read ENTIRE document_content:
        - Read all text including all chunks if divided
        - This tells you WHAT EXISTS TODAY and WHAT PROBLEMS exist
        - Extract FACTS, NUMBERS, NAMES, CURRENT PROCESSES from actual text

    (B) Read additional_instructions:
        - This tells you WHAT THEY WANT TO BUILD and WHY
        - Extract GOALS, OBJECTIVES, DESIRED FEATURES from instructions
        - Understand the VISION for the new system

    STEP 2 - EXTRACT FROM DOCUMENTS (document_content):

    From the actual text, extract:

    (1) STAKEHOLDERS & ACTORS:
        - Names, roles, companies mentioned in text
        - Teams, departments, user types described
        - Current and future actors

    (2) BUSINESS CONTEXT:
        - What business/organization is this for?
        - What industry/domain/sector?
        - What geography/region if mentioned?
        - Current situation, background

    (3) CURRENT PAIN POINTS:
        - Explicit problems mentioned in documents
        - Inefficiencies, bottlenecks, frustrations
        - Manual/repetitive/time-consuming work
        - What doesn't work well today?

    (4) CURRENT PROCESS & TOOLS:
        - How do they work today?
        - What tools/systems currently used?
        - What is the current workflow?
        - Team size, structure mentioned
        - Volumes, frequencies, metrics

    (5) QUANTITATIVE DATA (CRITICAL):
        - ALL NUMBERS: volumes, sizes, frequencies, counts
        - Performance metrics, success rates, percentages
        - Timings, durations, costs
        - Team sizes, resource counts

    (6) DOMAIN TERMINOLOGY:
        - Technical terms specific to their domain
        - Business rules, regulations mentioned
        - Data entities described
        - Workflows/processes detailed

    STEP 3 - EXTRACT FROM INSTRUCTIONS (additional_instructions):

    From the instructions, extract:

    (1) PROJECT GOALS:
        - What should the system achieve?
        - What problems should it solve?
        - Expected outcomes

    (2) DESIRED FEATURES:
        - What functionalities are requested?
        - What should the system do?
        - Modules or components mentioned

    (3) SYSTEM VISION:
        - What type of system (web app, mobile, API, desktop, etc.)?
        - Architecture hints or preferences
        - Technology preferences if mentioned

    (4) CONSTRAINTS:
        - Timeline, budget mentioned
        - Technical limitations
        - Regulatory requirements

    STEP 4 - COMBINE UNDERSTANDING:

    Merge insights from BOTH sources:
    - Documents tell you CURRENT STATE (as-is)
    - Instructions tell you DESIRED STATE (to-be)
    - Together they define what needs to be built

    STEP 5 - IDENTIFY DOMAIN:

    From both sources, determine:
    - Primary industry/sector
    - Type of application needed
    - Geographic context (if relevant for compliance)
    - Key technologies mentioned or implied

    IMPORTANT:
    - Extract ONLY what is in the text - do NOT invent
    - Use VERBATIM QUOTES as evidence
    - If information not present, state "not mentioned"
    - Process ALL chunks if document is divided
  expected_output: >
    JSON object with analysis from BOTH documents and instructions.

    Structure: Top-level object containing the following fields:
    - domain_identified: string describing primary industry or sector
    - from_documents: object with nested fields
      * stakeholders: array of strings with quotes from documents
      * business_context: string with key facts
      * pain_points: array of strings with evidence
      * current_process: string describing how they work
      * current_tools: array of tools mentioned
      * quantitative_data: array of numbers with verbatim quotes
      * domain_terminology: array of technical terms
    - from_instructions: object with nested fields
      * project_goals: array of goals
      * desired_features: array of features
      * system_vision: string describing system type
      * constraints: array of limitations
    - synthesis: object with nested fields
      * current_state: string with as-is summary
      * desired_state: string with to-be summary
      * gap: string describing what needs to change
    - extraction_status: string value "success" or "failed"
    - words_processed: integer count

extract_requirements:
  description: >
    [Requirements Extraction] Extract requirements from DOCUMENTS + INSTRUCTIONS, then INFER technical needs.

    YOU RECEIVE 3 INPUT SOURCES:
    - document_content: {document_content} (factual information from uploaded files)
    - additional_instructions: {additional_instructions} (project goals and context)
    - analysis_json: {analysis_json} (structured analysis from previous step)
    - project_name: {project_name}

    YOUR TASK HAS 4 PARTS:
    PART 1: Extract from DOCUMENTS
    PART 2: Extract from INSTRUCTIONS
    PART 3: INFER technical requirements
    PART 4: Prepare for WEB RESEARCH

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PART 1: EXTRACT FROM DOCUMENTS (document_content)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    From ACTUAL TEXT in documents, extract requirements:

    FUNCTIONAL REQUIREMENTS from documents:
    - MANUAL TASK mentioned â†’ FR to automate it
    - PAIN POINT mentioned â†’ FR to solve it
    - DATA/ENTITY mentioned â†’ CRUD FRs
    - INTEGRATION mentioned â†’ Integration FR
    - WORKFLOW described â†’ FRs for each step

    For EACH FR from documents:
    - Provide VERBATIM QUOTE as evidence
    - Mark source: "from_document"

    NON-FUNCTIONAL REQUIREMENTS from documents:
    - VOLUME/SCALE mentioned â†’ Performance NFR with that number
    - SPEED issues mentioned â†’ Response time NFR
    - TEAM SIZE mentioned â†’ Usability NFR
    - SENSITIVE DATA mentioned â†’ Security NFR

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PART 2: EXTRACT FROM INSTRUCTIONS (additional_instructions)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    From instructions provided by user:

    FUNCTIONAL REQUIREMENTS from instructions:
    - FEATURE requested â†’ FR
    - MODULE described â†’ FRs for that module
    - WORKFLOW described â†’ FRs for workflow steps

    For EACH FR from instructions:
    - Quote the instruction text
    - Mark source: "from_instructions"

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    CRITICAL - REQUIREMENT EXTRACTION LOGIC
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    YOUR PRIMARY SOURCE for functional requirements is INSTRUCTIONS (additional_instructions).

    STEP 1: Read additional_instructions
    - Identify each MODULE, FEATURE, or FUNCTIONALITY explicitly requested
    - Each one becomes a separate FR
    - Description should match what was requested (not generic "automation")
    - Example: If instructions say "Cadastro Inteligente do PortfÃ³lio", FR should be "Cadastro Inteligente do PortfÃ³lio", NOT "Automate portfolio management"

    STEP 2: Read document_content to ENRICH requirements
    - Look for PAIN POINTS that relate to the instructions
    - Look for WORKFLOWS that should be automated
    - Look for SPECIFIC CONSTRAINTS or REQUIREMENTS mentioned
    - Use these to add evidence and context, NOT to replace instruction-based FRs

    STEP 3: Combine both sources
    - FR description = What was requested in instructions (preserve original wording)
    - FR evidence = Quote from documents showing WHY it's needed or HOW it's currently done
    - FR context/details = Specific data from documents (volumes, names, locations)

    EXAMPLE OF CORRECT EXTRACTION:

    additional_instructions says: "Agente de IA para Captura e Leitura dos Certames"
    document_content says: "Farmac needs to monitor public procurement notices across Bahia, Sergipe, and Alagoas. Current manual process with 2-3 people."

    âœ… CORRECT:
    Requirement object with fields:
    - id: "FR-002"
    - description: "Agente de IA para captura e leitura dos certames de fontes pÃºblicas (federal, estaduais e municipais)"
    - source: "from_instructions"
    - evidence: "Current manual process with 2-3 person team monitoring procurement notices. Geographic scope: Bahia, Sergipe, and Alagoas."
    - priority: "high"
    - context: nested object with current_team_size "2-3 people", geographic_scope "Bahia, Sergipe, Alagoas", company "Farmac"

    âŒ WRONG (too generic, ignores instructions):
    Requirement with:
    - id: "FR-002"
    - description: "Automate the manual task of capturing procurement notices"
    - source: "from_document"
    - evidence: "Manual monitoring needed"

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    HANDLING SPECIFIC DATA FROM DOCUMENTS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    IF documents mention specific data, use it APPROPRIATELY:

    - Company name (e.g., "Farmac") â†’ Include in:
      * project_context section (NOT in every FR description)
      * actors/stakeholders
      * evidence field when relevant

    - Specific volumes (e.g., "10,000 items") â†’ Include in:
      * NFR for performance/scalability
      * Context field of related FRs
      * Evidence when showing scale of problem

    - Locations (e.g., "Bahia, Sergipe, Alagoas") â†’ Include in:
      * Scope definition
      * Geographic filtering requirement
      * Context of relevant FRs

    - People names (e.g., "Douglas") â†’ Include in:
      * Actors/stakeholders section
      * NOT in requirement descriptions

    DO NOT force specific data into every requirement.
    USE specific data to make requirements realistic and contextual.

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PART 3: INFER TECHNICAL REQUIREMENTS (not explicitly stated)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Based on extracted requirements, INFER necessary technical requirements:

    INFER DATA REQUIREMENTS:
    - Entities mentioned â†’ Database schema needed
    - Large volumes â†’ Indexing, optimization needed

    INFER INFRASTRUCTURE:
    - Web application â†’ Hosting needed
    - API mentioned â†’ API architecture needed

    INFER SECURITY:
    - User data â†’ Authentication needed
    - Sensitive data â†’ Encryption needed

    INFER MONITORING:
    - Production system â†’ Logging needed
    - Critical operations â†’ Error handling needed

    For EACH inferred requirement:
    - Mark source: "inferred"
    - Provide RATIONALE

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PART 4: PREPARE FOR WEB RESEARCH + CONTEXT EXTRACTION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    STEP 4A: EXTRACT BUSINESS CONTEXT FOR DOCUMENT (STRUCTURED JSON)

    From documents, extract and CREATE business_context object in your JSON output:

    business_context: JSON object with these fields:
      - geographic_scope: array of location strings
      - industry: single string with primary sector
      - company_type: string describing company type
      - products_services: array of main offering strings
      - target_market: string describing target customers
      - regulatory_bodies: array of regulatory body strings
      - domain_terminology: array of objects, each with "term" and "definition" fields
      - quantitative_data: object with team_size, portfolio_size, market_coverage, and other_metrics fields

    EXTRACTION RULES:

    1. GEOGRAPHIC SCOPE - Extract ALL locations mentioned:
       Example: ["Bahia", "Sergipe", "Alagoas", "Brazil"]
       If no locations: ["Not specified"]

    2. INDUSTRY - Single string with primary sector:
       Example: "Healthcare - Clinical Laboratory Supplies"
       Example: "Public Procurement - Government Bidding"

    3. COMPANY TYPE - What type of company:
       Example: "Distributor", "Manufacturer", "Service Provider", "Platform", "Marketplace"

    4. PRODUCTS/SERVICES - Array of main offerings:
       Example: ["Laboratory reagents", "Clinical analysis equipment", "Hospital supplies"]

    5. TARGET MARKET - Who are the customers:
       Example: "B2G (Business-to-Government) - Public hospitals and laboratories"

    6. REGULATORY BODIES - Extract ALL mentioned:
       Example: ["ANVISA", "Ministry of Health"]
       If none: []

    7. DOMAIN TERMINOLOGY - Extract 3-5 KEY terms with definitions:
       Example: array with objects containing term and definition fields
       - First object: term "Comodato", definition "Equipment loan contract where supplier provides equipment and consumables at unit price without fixed rental"
       - Second object: term "LicitaÃ§Ã£o", definition "Public procurement process for goods and services"
       - Third object: term "Edital", definition "Public tender notice document with requirements"

    8. QUANTITATIVE DATA - Extract specific numbers:
       Example: object with these fields
       - team_size: "2-3 people"
       - portfolio_size: "10,000 ANVISA-registered items"
       - market_coverage: "3 Brazilian states"

    This structured context will populate the "Context and Justification" section of the requirements document.

    STEP 4B: FORMULATE WEB RESEARCH QUERIES

    Identify domain and formulate 8-15 search queries.

    Make queries SPECIFIC to identified domain AND geography.

    LANGUAGE STRATEGY:
    - IF geographic context includes Brazil/Brasil/Portuguese â†’ Use PORTUGUESE queries
    - IF geographic context includes Spanish-speaking countries â†’ Use SPANISH queries
    - OTHERWISE â†’ Use ENGLISH queries

    EXAMPLE - Brazilian context detected:
    - "melhores prÃ¡ticas licitaÃ§Ãµes pÃºblicas brasil"
    - "Lei 14.133 requisitos sistema licitaÃ§Ã£o"
    - "integraÃ§Ã£o ComprasNet API brasil"
    - "sistemas gestÃ£o licitaÃ§Ãµes saÃºde brasil"

    EXAMPLE - US context detected:
    - "government procurement software best practices USA"
    - "FAR compliance requirements procurement systems"

    QUERY CATEGORIES (adapt to domain):
    1. Best practices in [domain] + [country/region]
    2. Legal/regulatory requirements [domain] + [country]
    3. Industry standards and compliance [domain]
    4. Similar systems/software [domain] + [country]
    5. Technical architecture patterns [domain]
    6. Integration standards [domain-specific systems]
    7. Security requirements [domain] + [country regulations]
    8. Performance benchmarks [domain]

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FINAL VALIDATION - CHECKLIST BEFORE RETURNING OUTPUT
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Before generating your output, COUNT and verify:

    âœ“ Each MODULE/FEATURE from additional_instructions has a corresponding FR
    âœ“ FR descriptions match the REQUESTED features (not generic "automation")
    âœ“ Evidence cites document_content showing WHY each requirement is needed
    âœ“ Specific data (company, volumes, locations) is in APPROPRIATE sections
    âœ“ I inferred technical requirements (database, API, security, monitoring)
    âœ“ Each inferred requirement has RATIONALE explaining why necessary

    âœ“ I extracted business_context object with ALL fields populated:
      - geographic_scope: array with locations
      - industry: string
      - company_type: string
      - regulatory_bodies: array (e.g., ANVISA, FDA)
      - domain_terminology: array of term/definition objects

    âœ“ I prepared 8-15 web_research_queries in APPROPRIATE LANGUAGE
      - Portuguese if Brazil/Brasil detected
      - Spanish if Hispanic countries detected
      - English otherwise

    âœ“ Web queries are SPECIFIC to domain + geography (not generic)

    RED FLAGS - DO NOT do this:
    âŒ FR says "Automate procurement" when instruction said "Agente de IA para captura"
    âŒ Company name appears in every FR description unnecessarily
    âŒ Generic "user login" FR when not requested in instructions
    âŒ Missing FRs for features explicitly requested in instructions
    âŒ Requirements with no source/evidence citation
    âŒ Invented stakeholders/companies not mentioned in documents
    âŒ Placeholder text like "TBD", "to be defined", "N/A" without explanation

    QUALITY CHECK - Count your FRs:
    - If additional_instructions lists 4 modules â†’ you should have ~4+ FRs from instructions
    - If you have many generic FRs but few instruction-based ones â†’ REVIEW AGAIN

    If ANY checkbox is unchecked, REVIEW inputs again before returning.

  expected_output: >
    JSON with requirements from 4 sources (documents, instructions, inferred, suggested).

    Structure: Top-level object with the following fields:

    - functional_requirements: array of requirement objects, each containing:
      * id: string like "FR-001", "FR-002", etc
      * description: string with requirement description
      * source: string value "from_document" or "from_instructions" or "inferred" or "from_web_research" or "suggested_by_ai"
      * evidence: string with verbatim quote (if from doc/instructions)
      * rationale: string with explanation (if inferred or suggested)
      * priority: string value "high" or "medium" or "low"

    - non_functional_requirements: array with same structure as functional_requirements

    - business_rules: array of business rule objects

    - entities: array of data entity objects

    - actors: array of actor/stakeholder objects with name and role

    - workflows: array of workflow objects

    - business_context: object containing:
      * geographic_scope: array of locations (countries, states, cities)
      * industry: string describing industry/sector
      * company_type: string (e.g., distributor, manufacturer)
      * products_services: array of products/services offered
      * target_market: string describing target customers
      * regulatory_bodies: array of regulatory bodies mentioned (e.g., ANVISA, FDA)
      * domain_terminology: array of objects with term and definition
      * quantitative_data: object with key business metrics

    - web_research_queries: array of strings with search queries in APPROPRIATE LANGUAGE for next step

research_additional_info:
  description: >
    [Web Research] Find ANALOGOUS SYSTEMS and BEST PRACTICES to enrich requirements.

    YOU RECEIVE:
    - requirements_json: {requirements_json} (extracted + inferred requirements)
    - web_research_queries: Suggested queries from previous step

    GOAL: Research similar/analogous systems to find:
    1. Features we might have missed
    2. Industry standards and best practices
    3. Technical recommendations
    4. Compliance requirements

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 1: UNDERSTAND THE SYSTEM TYPE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    From requirements_json understand:
    - What domain/industry?
    - What type of system?
    - Core functionalities?
    - Key challenges?

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 2: SEARCH FOR ANALOGOUS/SIMILAR SYSTEMS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Use serper_search tool to find similar systems:

    (A) EXISTING SOLUTIONS:
        Search: "[domain] [system type] software"
        Search: "open source [analogous system]"
        Goal: Find what features similar systems have

    (B) INDUSTRY STANDARDS:
        Search: "[domain] software best practices"
        Search: "[domain] system requirements"
        Goal: Identify standard requirements

    (C) TECHNICAL ARCHITECTURE:
        Search: "[system type] architecture patterns"
        Search: "technology stack for [use case]"
        Goal: Find recommended tech and patterns

    (D) COMPLIANCE:
        Search: "[domain] compliance requirements"
        Search: "[domain] regulations [country if identified]"
        Goal: Identify regulatory requirements

    (E) PERFORMANCE:
        Search: "[system type] performance benchmarks"
        Search: "[domain] SLA standards"
        Goal: Find realistic performance targets

    IMPORTANT:
    - Use serper_search for EACH query
    - Adapt queries to domain context
    - If domain has geographic specificity, add country to queries

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 3: EXTRACT INSIGHTS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    From search results extract:

    (1) FEATURES from analogous systems
    (2) BEST PRACTICES for this domain
    (3) TECHNICAL RECOMMENDATIONS
    (4) COMPLIANCE REQUIREMENTS
    (5) PERFORMANCE BASELINES

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 4: IDENTIFY GAPS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Compare findings with requirements_json:
    - What features are common in similar systems but missing?
    - What compliance requirements apply but weren't identified?
    - What technical requirements are standard but not included?

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ADAPT TO CONTEXT
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    If requirements indicate specific geography/regulations:
    - Add country/region to search queries
    - Search for local regulations
    - Find region-specific standards

    Example: If Brazil context evident, add "brasil" to queries

  expected_output: >
    JSON with web research findings.

    Structure: Top-level object with the following fields:

    - analogous_systems: array of system objects, each containing:
      * name: string with system name
      * description: string describing what it does
      * source_url: string with URL
      * key_features: array of feature strings
      * relevance: string explaining why similar

    - best_practices: array of best practice objects with sources

    - recommended_technologies: array of technology recommendation objects

    - compliance_requirements: array of compliance requirement objects

    - performance_benchmarks: object with benchmark data

    - potentially_missing_requirements: array of requirement objects, each containing:
      * type: string value "FR" or "NFR" or "BR"
      * description: string with requirement description
      * justification: string like "Found in X similar systems"
      * source: string with URL

enrich_requirements:
  description: >
    [Requirements Enrichment] Validate completeness and add critical missing requirements.

    YOU WILL RECEIVE:
    - requirements_json: {requirements_json} (extracted requirements from documents and instructions)
    - research_findings_json: {research_findings_json} (web research results)
    - business_context: {business_context} (domain, geography, industry info)
    - project_name: {project_name}

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 1 - VALIDATE COMPLETENESS FROM 3 SOURCES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Requirements should come from 3 SOURCES:

    SOURCE 1 - DOCUMENTS:
    âœ… Every major concept from documents has requirements
    âœ… Quantitative data reflected
    âœ… Tools/systems mentioned have integration requirements
    âœ… Pain points have solution requirements
    âœ… Each has source citation

    SOURCE 2 - INSTRUCTIONS:
    âœ… All requested features have FRs
    âœ… All modules described have FRs
    âœ… All goals addressable by requirements
    âœ… Each cites instruction text

    SOURCE 3 - INFERENCE + WEB RESEARCH:
    âœ… Technical infrastructure requirements present
    âœ… Security/auth if user data mentioned
    âœ… Industry standards referenced
    âœ… Missing requirements from analogous systems
    âœ… Each has rationale

    RED FLAGS (incomplete):
    âŒ No stakeholders/actors from documents
    âŒ No requirements for volumes/metrics mentioned
    âŒ Features from instructions ignored
    âŒ Missing technical infrastructure
    âŒ No security when sensitive data mentioned
    âŒ Industry standards not incorporated

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 2 - VERIFY INPUTS WERE USED
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    QUESTION 1: Does requirements_json mention SPECIFIC entities/data from documents?
    - Check: Concrete numbers, names, roles?
    - âœ“ YES â†’ Continue
    - âœ— NO â†’ REJECT: "Requirements too generic"

    QUESTION 2: Does requirements_json address ALL features from instructions?
    - Check: Every requested module/feature has requirements?
    - âœ“ YES â†’ Continue
    - âœ— NO â†’ REJECT: "Requirements incomplete"

    QUESTION 3: Are there inferred technical requirements?
    - Must include: Database, API, Security, Infrastructure
    - Check: At least 4-5 NFRs covering infrastructure
    - âœ“ YES â†’ Continue
    - âœ— NO â†’ REJECT: "Missing infrastructure planning"

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 3 - ADD CRITICAL MISSING REQUIREMENTS (AI SUGGESTIONS)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Based on requirements_json and business_context, ADD 5-10 production-critical requirements that are MISSING.

    ADD requirements for:

    1. LEGAL COMPLIANCE (if missing):
       - IF Brazil â†’ LGPD compliance
       - IF EU â†’ GDPR compliance
       - IF healthcare â†’ ANVISA, HIPAA
       - Audit trail and reporting

    2. OPERATIONAL EXCELLENCE (if missing):
       - Automated backup with RTO/RPO
       - Monitoring, alerting, health checks
       - Comprehensive logging
       - Error handling and recovery

    3. SECURITY (if missing):
       - MFA for admin access
       - Rate limiting and DDoS protection
       - Data encryption (rest and transit)
       - Access control

    4. PERFORMANCE & SCALABILITY (if missing):
       - Caching strategy
       - Database optimization
       - Load balancing
       - Performance benchmarks

    5. USER EXPERIENCE (if missing):
       - Mobile responsiveness
       - Accessibility (WCAG)
       - Internationalization if multi-region

    For EACH suggested requirement:
    - Assign new ID: continue numbering (e.g., FR-009, NFR-011)
    - Set source: "suggested_by_ai"
    - Provide rationale: WHY critical for THIS domain
    - Set priority: "high" or "medium"
    - Reference standards: LGPD, ANVISA, etc.

    IMPORTANT: Only ADD what's MISSING. Don't duplicate.

  expected_output: >
    JSON object with:
    {
      "validation_status": "APPROVED" or "REJECTED",
      "validation_message": "explanation if rejected",
      "enriched_requirements": {
        "functional_requirements": [...all FRs including AI-suggested],
        "non_functional_requirements": [...all NFRs including AI-suggested],
        "business_rules": [...all BRs including AI-suggested]
      },
      "ai_suggested_count": {
        "functional": number,
        "non_functional": number,
        "business_rules": number
      },
      "completeness_flags": {
        "has_document_requirements": true/false,
        "has_instruction_requirements": true/false,
        "has_infrastructure_requirements": true/false,
        "has_security_requirements": true/false,
        "has_compliance_requirements": true/false
      }
    }

validate_quality:
  description: >
    [Quality Validation] Review requirements quality, identify gaps, and assign severity.

    YOU WILL RECEIVE:
    - enriched_requirements: {enriched_requirements} (all requirements including AI suggestions)
    - business_context: {business_context}
    - project_name: {project_name}

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 1 - QUALITY VALIDATION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Review all requirements (original + suggested) for quality issues:

    (a) AMBIGUOUS LANGUAGE:
        - Identify vague terms ("fast", "scalable", "user-friendly", "secure")
        - Flag requirements without specific measurable criteria
        - Detect undefined terms not in glossary

    (b) CONFLICTS/CONTRADICTIONS:
        - Find requirements that contradict each other
        - Identify conflicting priorities
        - Detect inconsistent business rules

    (c) TESTABILITY:
        - Verify each requirement has clear acceptance criteria
        - Check for measurable metrics (numbers, percentages, time limits)
        - Ensure requirements are verifiable/testable

    (d) COMPLETENESS:
        - Verify all actors have defined responsibilities
        - Check all workflows have complete steps
        - Ensure all entities have attributes defined
        - Confirm all business rules have conditions and actions

    (e) TRACEABILITY:
        - Verify every requirement has source document citation
        - Check priority is assigned
        - Ensure dependencies are mapped

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 2 - COMPLETENESS EVALUATION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    (a) INFORMATION SUFFICIENCY:
        Assess if extracted information is sufficient for development to begin.
        Score 0-100 based on completeness of FR, NFR, BR, actors, entities, workflows.

    (b) CRITICAL GAPS:
        Identify missing critical information:
        - Missing functional areas (e.g., has "Create" but no "Update" or "Delete")
        - Missing non-functional requirements for key areas (security, performance)
        - Undefined actors or incomplete actor definitions
        - Missing error handling or exception scenarios

    (c) INFORMATION REQUESTS:
        Generate specific questions to fill gaps:
        - What information is needed
        - Why it's critical
        - What will be blocked without it

    (d) COVERAGE BY APPLICATION TYPE:
        Compare against standards for the application type identified:
        - Web app: authentication, session management, responsive design, browser support
        - API: authentication, rate limiting, versioning, error handling, documentation
        - Mobile: offline mode, push notifications, app permissions, device compatibility
        - Data platform: data pipeline, ETL, data quality, backup/recovery

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STEP 3 - ASSIGN SEVERITY TO ISSUES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    For each issue found, assign severity:
    - CRITICAL: Blocks development, security risk, regulatory violation
    - HIGH: Significant impact on functionality or quality
    - MEDIUM: Affects user experience or development efficiency
    - LOW: Minor issue, cosmetic, or nice-to-have improvement

  expected_output: >
    JSON object with:
    {
      "valid_requirements": [...requirements with quality scores],
      "issues_found": [
        {
          "type": "ambiguous|conflict|testability|completeness|traceability",
          "severity": "critical|high|medium|low",
          "description": "detailed description",
          "affected_requirement_id": "FR-001",
          "recommended_fix": "suggestion",
          "example_correction": "example"
        }
      ],
      "quality_scores": {
        "completeness_score": 0-100,
        "clarity_score": 0-100,
        "consistency_score": 0-100,
        "testability_score": 0-100,
        "traceability_score": 0-100
      },
      "completeness_breakdown": {
        "functional_requirements": 0-100,
        "non_functional_requirements": 0-100,
        "business_rules": 0-100,
        "actors": 0-100,
        "entities": 0-100,
        "workflows": 0-100
      },
      "coverage_analysis": {
        "covered_areas": [...],
        "missing_areas": [...]
      },
      "critical_gaps": [
        {
          "gap_type": "missing_functional_area|missing_nfr|undefined_actor",
          "severity": "critical|high",
          "description": "what's missing",
          "impact": "impact on development",
          "justification": "why critical"
        }
      ],
      "information_requests": [
        {
          "question": "specific question",
          "priority": "high|medium|low",
          "affected_requirements": ["FR-001"],
          "why_critical": "explanation"
        }
      ],
      "application_type_checklist": {
        "identified_type": "web|api|mobile|data_platform",
        "required_items": [...],
        "covered_items": [...],
        "missing_items": [...]
      }
    }

generate_document:
  description: >
    [Document Generation] Generate final professional requirements document with validation results.

    YOU WILL RECEIVE:
    - enriched_requirements: {enriched_requirements} (all requirements)
    - quality_validation: {quality_validation} (quality scores, issues, gaps)
    - research_findings_json: {research_findings_json} (web research)
    - template: {template} (Markdown template)
    - project_name: {project_name}

    CRITICAL INSTRUCTIONS:
    This is the FINAL REQUIREMENTS DOCUMENT for stakeholders.
    Must be COMPLETE, PROFESSIONAL, ACCURATE, and TRACEABLE.

    DO NOT USE PLACEHOLDER TEXT:
    - NO "To be filled by analysis"
    - NO "TBD" or "N/A" without explanation
    - If data is missing, state what's missing and why

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    INDICADORES DE ORIGEM (CRITICAL - MUST IMPLEMENT)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Add "Origem" column to ALL requirement tables:

    MAPPING:
    - source "from_document" â†’ ðŸ”´ RED (Requisito ExtraÃ­do do Documento)
    - source "from_instructions" â†’ ðŸ“˜ REI (Requisito ExtraÃ­do das InstruÃ§Ãµes)
    - source "inferred" â†’ ðŸ”§ RI (Requisito Inferido pelo LLM)
    - source "from_web_research" â†’ ðŸŒ RW (Requisito da Web Research)
    - source "suggested_by_ai" â†’ ðŸ¤– RIA (Requisito sugerido pela IA)

    FORMAT: emoji + space + abbreviation (e.g., "ðŸ”´ RED", "ðŸ“˜ REI")

    LEGEND (add BEFORE Section 3.1):

    ### Legenda de Indicadores de Origem

    | Indicador | Significado | DescriÃ§Ã£o |
    |-----------|-------------|-----------|
    | ðŸ”´ RED | Requisito ExtraÃ­do do Documento | Identificado diretamente nos documentos fornecidos |
    | ðŸ“˜ REI | Requisito ExtraÃ­do das InstruÃ§Ãµes | Especificado nas instruÃ§Ãµes do usuÃ¡rio |
    | ðŸ”§ RI | Requisito Inferido | Deduzido pelo LLM com base no contexto tÃ©cnico |
    | ðŸŒ RW | Requisito da Web Research | Identificado atravÃ©s de pesquisa complementar |
    | ðŸ¤– RIA | Requisito Sugerido pela IA | Adicionado pela IA para sistema production-ready |

    ---

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STRUCTURE - ORGANIZE BY SOURCE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ## 3. Requisitos Funcionais (FR)

    ### 3.1 Requisitos ExtraÃ­dos dos Documentos (ðŸ”´ RED)
    | ID | Origem | Nome | DescriÃ§Ã£o | Prioridade | Atores | DependÃªncias | CritÃ©rios |
    |----|--------|------|-----------|------------|--------|--------------|-----------|
    | FR-001 | ðŸ”´ RED | ... | ... | ... | ... | ... | ... |

    **Total: X requisitos extraÃ­dos dos documentos**

    ---

    ### 3.2 Requisitos das InstruÃ§Ãµes do UsuÃ¡rio (ðŸ“˜ REI)
    | ID | Origem | Nome | DescriÃ§Ã£o | Prioridade | Atores | DependÃªncias | CritÃ©rios |
    |----|--------|------|-----------|------------|--------|--------------|-----------|
    | FR-005 | ðŸ“˜ REI | ... | ... | ... | ... | ... | ... |

    **Total: Y requisitos das instruÃ§Ãµes**

    ---

    ### 3.3 Requisitos Inferidos pelo LLM (ðŸ”§ RI)
    | ID | Origem | Nome | DescriÃ§Ã£o | Prioridade | Atores | DependÃªncias | CritÃ©rios |
    |----|--------|------|-----------|------------|--------|--------------|-----------|
    | FR-010 | ðŸ”§ RI | ... | ... | ... | ... | ... | ... |

    **Total: Z requisitos inferidos**

    ---

    ### 3.4 Requisitos da Pesquisa Web (ðŸŒ RW)

    IF requirements with source="from_web_research":
    | ID | Origem | Nome | DescriÃ§Ã£o | Prioridade | Atores | DependÃªncias | CritÃ©rios |
    |----|--------|------|-----------|------------|--------|--------------|-----------|
    | FR-015 | ðŸŒ RW | ... | ... | ... | ... | ... | ... |

    **Total: W requisitos da web**

    IF NO requirements with source="from_web_research":
    âš ï¸ **A pesquisa web foi realizada, mas nÃ£o identificou requisitos funcionais adicionais relevantes para este domÃ­nio especÃ­fico. A anÃ¡lise web focou em melhores prÃ¡ticas e padrÃµes (ver SeÃ§Ã£o 13).**

    ---

    ### 3.5 Requisitos Sugeridos pela IA (ðŸ¤– RIA)
    | ID | Origem | Nome | DescriÃ§Ã£o | Prioridade | Atores | DependÃªncias | CritÃ©rios |
    |----|--------|------|-----------|------------|--------|--------------|-----------|
    | FR-020 | ðŸ¤– RIA | ... | ... | ... | ... | ... | ... |

    **Total: V requisitos sugeridos pela IA**

    ---

    ### 3.6 CONSOLIDADO - Todos os Requisitos Funcionais
    (Single table with ALL FRs ordered by ID, including Origem column)

    **Total Geral: XX requisitos funcionais**

    APPLY SAME STRUCTURE FOR:
    - Section 4 (Non-Functional Requirements): 4.1=RED, 4.2=REI, 4.3=RI, 4.4=RW, 4.5=RIA, 4.6=Consolidado
    - Section 5 (Business Rules): 5.1=RED, 5.2=REI, 5.3=RI, 5.4=RW, 5.5=RIA, 5.6=Consolidado

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    TEMPLATE FILLING RULES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - Replace PROJECT_NAME with actual project name
    - Fill PROJECT_DOMAIN with identified domain
    - Populate all requirement lists with actual requirements
    - Add ORIGEM column with indicators (ðŸ”´ RED, ðŸ“˜ REI, ðŸ”§ RI, ðŸŒ RW, ðŸ¤– RIA)
    - Generate mermaid diagrams with actual data (entities, workflows, dependencies)
    - Use research findings for "Best Practices" and "Standards" sections
    - Fill compliance checklist with actual compliance needs
    - Add actual glossary terms from documents
    - Populate metadata sections with real statistics

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    CONTEXT AND JUSTIFICATION SECTION (Section 1.2)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Use business_context to create RICH, DETAILED context:

    - Geographic Scope: All countries, states, regions, cities from geographic_scope
    - Industry Context: industry, company_type, products_services, target_market
    - Regulatory Environment: regulatory_bodies and compliance needs
    - Domain Specifics: domain_terminology with definitions
    - Business Scale: quantitative_data

    If business_context missing: "Context information is limited. Additional stakeholder interviews recommended."

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    QUALITY CHECKS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - Minimum 20 requirements total (unless documents very small)
    - Every requirement has source citation
    - Every technical term in glossary
    - All mermaid diagrams use real entity/requirement names
    - Completeness score â‰¥ 70% for each category
    - No placeholder text remaining

  expected_output: >
    RETURN ONLY VALID JSON. Do NOT add markdown code blocks. Do NOT add explanatory text after JSON.

    {
      "requirements_document_md": "# COMPLETE Markdown document here...",
      "document_metadata": {
        "total_requirements": number,
        "functional_count": number,
        "non_functional_count": number,
        "business_rules_count": number,
        "pages_estimated": number,
        "completeness_score": 0-100
      },
      "quality_summary": {
        "overall_quality_score": 0-100,
        "critical_issues_count": number,
        "high_issues_count": number,
        "medium_issues_count": number,
        "low_issues_count": number
      },
      "source_distribution": {
        "from_documents": number,
        "from_instructions": number,
        "inferred": number,
        "from_web_research": number,
        "suggested_by_ai": number
      }
    }

    CRITICAL: requirements_document_md field MUST contain complete document. NO empty strings or placeholders.

generate_specification:
  description: >
    Create comprehensive functional specification document from validated requirements: {validated_requirements}. Structure: (1) Introduction with project overview and scope; (2) Functional Requirements organized by module with IDs (FR-001, FR-002); (3) Non-Functional Requirements with metrics; (4) Data Model with entities and relationships; (5) User Workflows with step-by-step descriptions; (6) Business Rules with conditions/actions; (7) Glossary; (8) Traceability matrix linking requirements to use cases. Use Markdown with mermaid diagrams.
  expected_output: >
    Complete Markdown document following IEEE 830 standard structure with: section hierarchy using ## headers, numbered requirements with cross-references, tables for data models, mermaid diagrams for workflows (```mermaid syntax), proper formatting (bold/italic), and full traceability matrix.

# Agent Design Tasks
suggest_agents:
  description: >
    Analyze requirements: {requirements_json} and specification: {specification_data}. Suggest optimal agent architecture defining: (1) Agent roles and responsibilities based on requirement types; (2) Goals for each agent aligned with requirements; (3) Backstories providing context and expertise; (4) Tool assignments (which agents need which tools); (5) Delegation patterns (which agents can delegate to others); (6) Communication flows between agents. Optimize for separation of concerns and minimize overlapping responsibilities.
  expected_output: >
    JSON object with 'agents' array containing: agent_id, name, role, goal, backstory, tools (array), verbose (bool), allow_delegation (bool), delegation_targets (array of agent_ids), estimated_complexity (low/medium/high), justification (why this agent is needed).

decompose_tasks:
  description: >
    Break down requirements: {requirements_json} into executable tasks for agents: {agents_json}. For each task define: (1) Unique task_id; (2) Clear description with placeholders for inputs; (3) Expected output format (JSON/Markdown/CSV); (4) Assigned agent_id; (5) Required tools; (6) Dependencies on other tasks (task_ids); (7) Async execution flag; (8) Input schema; (9) Output schema. Tasks should be atomic, testable, and properly sequenced.
  expected_output: >
    JSON object with: (1) 'tasks' array with task definitions; (2) 'dependencies' object mapping task_id to array of required task_ids; (3) 'execution_order' array suggesting optimal task sequence; (4) 'parallel_groups' array of tasks that can run in parallel; (5) 'estimated_duration' for each task.

# Workflow Design Tasks
design_petri_net:
  description: >
    Design Petri Net workflow from tasks: {tasks_json}, dependencies: {dependencies}, and agents: {agents_json}. Define: (1) Places (workflow states) with initial token distribution; (2) Transitions (task executions) with guard conditions; (3) Arcs connecting places to transitions with weights; (4) Agent assignments to places; (5) Input/output data flow; (6) Error handling paths; (7) Synchronization points for parallel tasks. Ensure workflow is sound (no deadlocks, livelocks).
  expected_output: >
    JSON Petri Net model with: 'places' array (id, name, tokens, agent_id, input_data, output_data, logic), 'transitions' array (id, name, guard), 'arcs' array (source, target, weight), 'agents' array (id, name, coordinates), workflow_properties (is_sound, has_deadlocks, estimated_cycles).

# Code Generation Tasks
generate_yaml_files:
  description: >
    Generate YAML configuration files from agents: {agents_json} and tasks: {tasks_json}. Create: (1) agents.yaml with each agent's role, goal, backstory, verbose, allow_delegation following CrewAI format; (2) tasks.yaml with each task's description (with placeholders), expected_output, and any task-specific config. Follow YAML best practices: proper indentation (2 spaces), use '>' for multi-line strings, include comments for clarity.
  expected_output: >
    JSON object with: (1) 'agents_yaml': complete agents.yaml content as string; (2) 'tasks_yaml': complete tasks.yaml content as string; (3) 'validation_status': whether YAML is valid; (4) 'warnings': array of potential issues or improvements.

generate_python_code:
  description: >
    Generate production-ready Python code implementing multi-agent system using framework: {framework_choice}. Include: (1) Imports and dependencies; (2) Agent initialization from YAML; (3) Tool creation and registration; (4) Task definitions with input/output functions; (5) Task Registry; (6) Workflow executor; (7) Main orchestration logic; (8) Error handling and logging; (9) Type hints and docstrings; (10) Entry point with CLI. Follow PEP 8, include comments, make code modular and testable.
  expected_output: >
    JSON object with: (1) 'main_file': complete Python code as string; (2) 'additional_files': dict of filename to content for supporting files (utils, config, etc); (3) 'requirements_txt': Python dependencies; (4) 'readme_md': usage documentation; (5) 'test_file': basic test suite.

# =============================================================================
# SPECIFICATION GENERATION TASKS (Multi-Step Pipeline)
# Based on Generative Computing principles - IBM Research
# Pipeline: Router â†’ EntityExtractor â†’ Composer â†’ Verifier â†’ Compliance â†’ Formatter
# =============================================================================

classify_specification_intent:
  description: >
    [Specification Router] Classify the specification generation task intent and determine pipeline.

    YOU RECEIVE:
    - requirements_document: {requirements_document}
    - requirements_version: {requirements_version}
    - project_name: {project_name}
    - detail_level: {detail_level}
    - target_audience: {target_audience}

    YOUR TASK:

    1. ANALYZE the requirements document to determine:
       - Is this a CREATE (new specification), UPDATE (modify existing), or VALIDATE (check consistency) task?
       - What is the scope of the specification needed?
       - Which of the 14 mandatory sections need to be generated?

    2. DETERMINE TARGET SECTIONS (all 14 are mandatory for CREATE):
       1. IntroduÃ§Ã£o
       2. VisÃ£o Geral do Sistema
       3. Requisitos Funcionais Detalhados
       4. Requisitos NÃ£o-Funcionais
       5. Casos de Uso (MÃNIMO 10 detalhados)
       6. Modelo de Dados Conceitual
       7. Interfaces do Sistema
       8. Regras de NegÃ³cio
       9. Fluxos de Trabalho
       10. AnÃ¡lise de Arquitetura Preliminar
       11. Controle de Qualidade
       12. GlossÃ¡rio
       13. Rastreabilidade (Matriz)
       14. ApÃªndices

    3. ASSESS complexity based on:
       - Number of functional requirements
       - Number of actors/stakeholders
       - Number of integrations
       - Domain complexity

    SCHEMA OUTPUT REQUIRED - Return ONLY valid JSON.

  expected_output: >
    Return a JSON object with these fields:
    - intent: one of create, update, or validate
    - scope: functional_spec
    - target_sections: array of section numbers from 1 to 14
    - requirements_version: the version number
    - project_name: name of the project
    - detail_level: one of basic, detailed, or comprehensive
    - target_audience: one of technical, business, or mixed
    - estimated_complexity: one of low, medium, or high
    - estimated_use_cases: estimated number of use cases
    - estimated_business_rules: estimated number of business rules
    - routing_decision: description of the routing decision made

extract_specification_entities:
  description: >
    [Entity Extraction] Extract ALL entities from requirements document for specification.

    YOU RECEIVE:
    - requirements_document: {requirements_document}
    - classification_json: {classification_json}
    - project_name: {project_name}

    YOUR TASK: Extract EVERY entity from the requirements document with FULL TRACEABILITY.

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    EXTRACTION CATEGORIES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    1. ACTORS (stakeholders, users, systems):
       For each actor extract:
       - id: A-XXX (sequential)
       - name: Actor name
       - type: human|system|external
       - role: Description of role
       - permissions: What they can do
       - context_id: Reference to source in requirements
       - quote: Verbatim text from requirements

    2. FUNCTIONAL REQUIREMENTS:
       For each FR extract:
       - id: FR-XXX (use existing IDs from requirements if present)
       - name: Short name
       - description: Full description
       - priority: Alta|MÃ©dia|Baixa
       - acceptance_criteria: List of measurable criteria
       - dependencies: Related FRs
       - actors_involved: List of actor IDs
       - context_id: Reference to source
       - quote: Verbatim text

    3. NON-FUNCTIONAL REQUIREMENTS:
       For each RNF extract:
       - id: RNF-XXX
       - category: Performance|SeguranÃ§a|Usabilidade|Confiabilidade|Manutenibilidade
       - description: Full description
       - metric: Measurable metric (e.g., "< 2 segundos")
       - context_id: Reference to source
       - quote: Verbatim text

    4. USE CASES (MINIMUM 10):
       For each UC extract:
       - id: UC-XXX
       - name: Use case name
       - primary_actor: Actor ID
       - secondary_actors: List of actor IDs
       - related_frs: List of FR IDs
       - preconditions: List of conditions
       - postconditions: List of conditions
       - context_id: Reference to source

    5. BUSINESS RULES:
       For each RN extract:
       - id: RN-XXX
       - name: Rule name
       - condition: When does it apply
       - action: What must happen
       - validation: How to verify
       - related_frs: List of FR IDs
       - context_id: Reference to source
       - quote: Verbatim text

    6. DATA ENTITIES:
       For each entity extract:
       - name: Entity name
       - attributes: List of (name, type, required, description)
       - relationships: List of (related_entity, type, cardinality)
       - context_id: Reference to source

    7. APIS/INTERFACES:
       For each API extract:
       - name: API name
       - type: REST|SOAP|GraphQL|gRPC|Integration
       - method: GET|POST|PUT|DELETE|etc
       - path: Endpoint path
       - input: Input schema
       - output: Output schema
       - context_id: Reference to source

    8. WORKFLOWS:
       For each workflow extract:
       - name: Workflow name
       - steps: List of (step_number, description, actor, system_action)
       - triggers: What starts the workflow
       - outcomes: Possible outcomes
       - context_id: Reference to source

    9. GAPS AND QUESTIONS:
       Identify missing information:
       - type: missing_actor|missing_rule|ambiguous_requirement|undefined_term
       - description: What is missing
       - question: Specific question to clarify
       - impact: What cannot be specified without this

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    CRITICAL RULES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - EVERY item MUST have a context_id tracing to source
    - NEVER invent information not in requirements
    - If unsure, mark as GAP with question
    - Extract VERBATIM quotes as evidence
    - Maintain sequential IDs within each category

    SCHEMA OUTPUT REQUIRED - Return ONLY valid JSON.

  expected_output: >
    Return a JSON object with these arrays and objects:

    actors: array of objects with fields id (A-XXX format), name, type, role, permissions array, context_id, quote

    functional_requirements: array of objects with fields id (FR-XXX format), name, description, priority, acceptance_criteria array, dependencies array, actors_involved array, context_id, quote

    non_functional_requirements: array of objects with fields id (RNF-XXX format), category, description, metric, context_id, quote

    use_cases: array of objects with fields id (UC-XXX format), name, primary_actor, secondary_actors array, related_frs array, preconditions array, postconditions array, context_id

    business_rules: array of objects with fields id (RN-XXX format), name, condition, action, validation, related_frs array, context_id, quote

    data_entities: array of objects with fields name, attributes array, relationships array, context_id

    apis: array of objects with fields name, type, method, path, input object, output object, context_id

    workflows: array of objects with fields name, steps array, triggers array, outcomes array, context_id

    gaps: array of objects with fields type, description, question, impact

    extraction_summary: object with fields total_actors, total_frs, total_rnfs, total_ucs, total_rns, total_entities, total_apis, total_workflows, total_gaps (all numbers)

research_specification_context:
  description: >
    [Specification Web Research] Find relevant technical standards, best practices, and industry references to enrich the functional specification.

    YOU RECEIVE:
    - entities_json: {entities_json} (extracted entities with context_ids)
    - project_name: {project_name}

    YOUR TASK:
    1. Analyze extracted entities to identify key technical domains (authentication, payments, data storage, etc.)
    2. Research relevant technical standards:
       - ISO standards (ISO 27001 security, ISO 25010 quality)
       - IEEE standards (IEEE 830 requirements)
       - OWASP guidelines (security best practices)
       - WCAG (accessibility if applicable)
    3. Research compliance requirements based on domain:
       - LGPD/GDPR for personal data
       - PCI-DSS for payments
       - SOX for financial data
       - HIPAA for health data
    4. Find industry best practices for similar systems
    5. Identify reference architectures and patterns

    SEARCH STRATEGY:
    - Use specific domain + standard queries (e.g., "authentication OWASP best practices")
    - Search for compliance requirements by data type
    - Look for architectural patterns by system type
    - Prioritize authoritative sources (official standard bodies, recognized institutions)

    IMPORTANT:
    - Only include findings with clear source citations
    - Focus on standards and practices relevant to the extracted entities
    - Do not invent or extrapolate - only report verified findings
    - Limit to 3-5 most relevant items per category

  expected_output: >
    Return a JSON object with these fields:
    - technical_standards: array of objects with fields name (standard name), description (brief description), relevance (why relevant to this project), source (URL or reference)
    - compliance_requirements: array of objects with fields name (requirement name), description (brief description), applicability (when this applies), source (URL or reference)
    - best_practices: array of objects with fields name (practice name), description (brief description), recommendation (how to apply), source (URL or reference)
    - reference_architectures: array of objects with fields name (architecture name), description (brief description), applicability (when to use), source (URL or reference)
    - research_summary: object with fields total_standards (number), total_compliance (number), total_practices (number), total_architectures (number), domains_researched (array of domain names)

  agent: specification_web_researcher_agent
  tools:
    - tavily_search_tool
    - serpapi_search_tool
    - serper_search_tool

compose_specification_sections:
  description: >
    [Specification Composition] Generate ALL 14 sections of functional specification document.

    YOU RECEIVE:
    - entities_json: {entities_json} (extracted entities with context_ids)
    - research_context_json: {research_context_json} (web research findings: standards, compliance, best practices)
    - requirements_document: {requirements_document}
    - project_name: {project_name}
    - requirements_version: {requirements_version}
    - requirements_created_at: {requirements_created_at}
    - detail_level: {detail_level}
    - target_audience: {target_audience}

    IMPORTANT: Use research_context_json to enrich the specification with:
    - References to applicable technical standards in section 2 (Scope)
    - Compliance requirements in sections 6 (Security) and 10 (Constraints)
    - Industry best practices throughout the document
    - Reference architectures when describing system components

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    DOCUMENT STRUCTURE - ALL 14 SECTIONS MANDATORY
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Generate each section in Markdown format following this structure:

    # EspecificaÃ§Ã£o Funcional - {project_name}

    **VersÃ£o:** 1.0
    **Data:** {requirements_created_at}
    **Baseado em:** Requisitos v{requirements_version}

    ---

    ## 1. IntroduÃ§Ã£o

    ### 1.1 Objetivo do Documento
    Descrever o propÃ³sito desta especificaÃ§Ã£o funcional.

    ### 1.2 Escopo do Sistema
    Definir claramente o que estÃ¡ dentro e fora do escopo.

    ### 1.3 DefiniÃ§Ãµes, AcrÃ´nimos e AbreviaÃ§Ãµes
    Listar termos importantes para entendimento do documento.

    ### 1.4 ReferÃªncias
    - Documento de Requisitos v{requirements_version}

    ---

    ## 2. VisÃ£o Geral do Sistema

    ### 2.1 Perspectiva do Sistema
    ### 2.2 Principais Funcionalidades
    ### 2.3 UsuÃ¡rios e CaracterÃ­sticas
    ### 2.4 RestriÃ§Ãµes Gerais
    ### 2.5 Premissas e DependÃªncias

    ---

    ## 3. Requisitos Funcionais Detalhados

    Para CADA RF do entities_json, gerar:

    **RF-XXX: [Nome do Requisito]**
    - **DescriÃ§Ã£o:** [DescriÃ§Ã£o completa]
    - **Prioridade:** [Alta/MÃ©dia/Baixa]
    - **Origem:** [context_id - Rastreamento para documento de requisitos]
    - **CritÃ©rios de AceitaÃ§Ã£o:**
      1. [CritÃ©rio mensurÃ¡vel 1]
      2. [CritÃ©rio mensurÃ¡vel 2]
    - **Regras de NegÃ³cio Associadas:** [RN-XXX, RN-YYY]
    - **DependÃªncias:** [FR-AAA, FR-BBB]

    ---

    ## 4. Requisitos NÃ£o-Funcionais

    ### 4.1 Requisitos de Performance
    ### 4.2 Requisitos de SeguranÃ§a
    ### 4.3 Requisitos de Usabilidade
    ### 4.4 Requisitos de Confiabilidade
    ### 4.5 Requisitos de Manutenibilidade

    ---

    ## 5. Casos de Uso

    âš ï¸ INSTRUÃ‡Ã•ES CRÃTICAS PARA CASOS DE USO:
    1. Criar UC para CADA requisito funcional principal (MÃNIMO 10 UCs)
    2. CADA UC DEVE ter:
       - 5-10 passos detalhados no fluxo principal
       - 2-3 fluxos alternativos completos
       - 2-3 fluxos de exceÃ§Ã£o com tratamento
       - PrÃ©-condiÃ§Ãµes e pÃ³s-condiÃ§Ãµes especÃ­ficas
    3. NÃƒO resumir - detalhar CADA passo com aÃ§Ãµes concretas
    4. Incluir interaÃ§Ãµes de UI quando aplicÃ¡vel
    5. Referenciar TODOS os RFs relacionados

    ### 5.1 Diagrama de Casos de Uso
    [Lista de todos os atores e casos de uso]

    ### 5.2 EspecificaÃ§Ã£o Detalhada de Casos de Uso

    Para CADA caso de uso (MÃNIMO 10):

    **UC-XXX: [Nome do Caso de Uso]**
    - **Ator Principal:** [Nome do perfil de usuÃ¡rio]
    - **Atores SecundÃ¡rios:** [Outros envolvidos]
    - **Objetivo:** [O que o ator deseja alcanÃ§ar]
    - **PrÃ©-condiÃ§Ãµes:**
      1. [CondiÃ§Ã£o especÃ­fica 1]
      2. [CondiÃ§Ã£o especÃ­fica 2]
    - **Fluxo Principal:** (MÃNIMO 5-10 PASSOS)
      1. [Ator/Sistema] [AÃ§Ã£o detalhada com contexto]
      2. [Ator/Sistema] [PrÃ³xima aÃ§Ã£o especÃ­fica]
      3. [Sistema] [ValidaÃ§Ã£o ou processamento]
      4. [Sistema] [ExibiÃ§Ã£o de resultado ou feedback]
      5. [Ator] [ConfirmaÃ§Ã£o ou prÃ³xima interaÃ§Ã£o]
      6. ...
    - **Fluxos Alternativos:** (MÃNIMO 2)
      - A1. [CondiÃ§Ã£o]: [DescriÃ§Ã£o do fluxo alternativo completo]
      - A2. [CondiÃ§Ã£o]: [DescriÃ§Ã£o do fluxo alternativo completo]
    - **Fluxos de ExceÃ§Ã£o:** (MÃNIMO 2)
      - E1. [Erro/Problema]: [Como o sistema trata, mensagem exibida]
      - E2. [Erro/Problema]: [Tratamento e recuperaÃ§Ã£o]
    - **PÃ³s-condiÃ§Ãµes:**
      1. [Estado do sistema apÃ³s execuÃ§Ã£o bem-sucedida]
      2. [Dados alterados ou criados]
    - **Regras de NegÃ³cio AplicÃ¡veis:** [RN-XXX, RN-YYY]
    - **Requisitos Relacionados:** [RF-XXX, RF-YYY, RNF-ZZZ]
    - **Origem:** [context_id]

    ---

    ## 6. Modelo de Dados Conceitual

    ### 6.1 Entidades Principais
    ### 6.2 Relacionamentos
    ### 6.3 Atributos Principais
    ### 6.4 Regras de Integridade

    ---

    ## 7. Interfaces do Sistema

    ### 7.1 Interfaces de UsuÃ¡rio
    ### 7.2 Interfaces de Hardware
    ### 7.3 Interfaces de Software (APIs)
    ### 7.4 Interfaces de ComunicaÃ§Ã£o

    ---

    ## 8. Regras de NegÃ³cio

    Para CADA RN do entities_json:

    **RN-XXX: [Nome da Regra]**
    - **DescriÃ§Ã£o:** [Regra detalhada]
    - **CondiÃ§Ãµes:** [Quando se aplica]
    - **AÃ§Ãµes:** [O que deve acontecer]
    - **ValidaÃ§Ãµes:** [VerificaÃ§Ãµes necessÃ¡rias]
    - **Requisitos Relacionados:** [RF-XXX]
    - **Origem:** [context_id]

    ---

    ## 9. Fluxos de Trabalho

    ### 9.1 Processos Principais
    ### 9.2 InteraÃ§Ãµes entre Componentes
    ### 9.3 SequÃªncias CrÃ­ticas

    ---

    ## 10. AnÃ¡lise de Arquitetura Preliminar

    ### 10.1 Componentes e ServiÃ§os NecessÃ¡rios
    ### 10.2 PadrÃµes de InteraÃ§Ã£o
    ### 10.3 IntegraÃ§Ãµes Externas
    ### 10.4 ConsideraÃ§Ãµes de Performance
    ### 10.5 ConsideraÃ§Ãµes de SeguranÃ§a
    ### 10.6 ConsideraÃ§Ãµes de Escalabilidade
    ### 10.7 Tecnologias Recomendadas

    ---

    ## 11. Controle de Qualidade

    ### 11.1 CritÃ©rios de AceitaÃ§Ã£o Gerais
    ### 11.2 EstratÃ©gia de Testes
    ### 11.3 Riscos Identificados
    ### 11.4 Complexidades Previstas

    ---

    ## 12. GlossÃ¡rio

    Lista alfabÃ©tica de termos tÃ©cnicos e de domÃ­nio:
    **[Termo]:** [DefiniÃ§Ã£o clara e concisa]

    ---

    ## 13. Rastreabilidade

    ### 13.1 Matriz de Rastreabilidade
    | Requisito Original | SeÃ§Ã£o | RF | UC | RN |
    |--------------------|-------|----|----|-----|
    | [context_id] | [SeÃ§Ã£o X.Y] | RF-XXX | UC-XXX | RN-XXX |

    ---

    ## 14. ApÃªndices

    ### 14.1 HistÃ³rico de VersÃµes
    | VersÃ£o | Data | DescriÃ§Ã£o | Autor |
    |--------|------|-----------|-------|
    | 1.0 | {requirements_created_at} | VersÃ£o inicial | Sistema |

    ### 14.2 AprovaÃ§Ãµes

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    CRITICAL RULES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - ALL 14 sections are MANDATORY
    - EVERY item must have context_id for traceability
    - MINIMUM 10 detailed use cases with 5-10 steps each
    - NEVER invent information not in entities_json
    - If information missing, mark as GAP with question
    - Use pt-BR language, no first person

    SCHEMA OUTPUT REQUIRED - Return ONLY valid JSON.

  expected_output: >
    Return a JSON object with these fields:

    sections: array of 14 section objects, each with fields number, title, content (Markdown text), subsections array, context_ids array, status (complete or partial or gap)

    document_md: the complete Markdown document as a single string

    use_cases_count: total number of use cases generated

    use_cases_with_min_steps: number of use cases with at least 5 steps

    business_rules_count: total number of business rules

    traceability_entries: number of entries in traceability matrix

    gaps: array of gap objects with fields section (number), description, question

    generation_summary: object with fields total_sections (14), complete_sections, partial_sections, gap_sections, total_words (all numbers)

verify_specification_grounding:
  description: >
    [Grounding Verification] Validate each specification item against requirements.

    YOU RECEIVE:
    - draft_sections_json: {draft_sections_json}
    - entities_json: {entities_json}
    - requirements_document: {requirements_document}

    YOUR TASK: Verify that EVERY specification item has supporting context from requirements.

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    VERIFICATION TASKS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    1. FOR EACH FUNCTIONAL REQUIREMENT (RF-XXX):
       - Check context_id exists in requirements
       - Verify quote matches source text
       - Confirm acceptance criteria are derivable from requirements
       - Mark status: supported | unsupported | ambiguous

    2. FOR EACH USE CASE (UC-XXX):
       - Verify related FRs exist in entities
       - Check all steps have basis in requirements
       - Verify pre/post conditions are grounded
       - Flag any extrapolated steps

    3. FOR EACH BUSINESS RULE (RN-XXX):
       - Verify condition/action grounded in requirements
       - Check related FRs exist
       - Confirm validation logic is supported

    4. FOR EACH DATA ENTITY:
       - Verify entity mentioned in requirements
       - Check attributes have basis
       - Confirm relationships are documented

    5. CONSISTENCY CHECK:
       - No contradictions between sections
       - All cross-references valid (FR-XXX, UC-XXX, RN-XXX)
       - IDs are consistent and sequential
       - No orphan references

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ISSUE CATEGORIES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - unsupported: Item not found in requirements document
    - ambiguous: Multiple interpretations possible
    - inconsistent_with_requirements: Contradicts requirements
    - extrapolation: Information added not present in source
    - broken_reference: Cross-reference to non-existent item
    - format_violation: Does not follow required structure

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    RECOMMENDED ACTIONS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    For each issue, recommend ONE action:
    - retry_with_context: Try again with more context
    - request_additional_source: Ask for more information
    - remove_unsourced: Delete item without source
    - move_to_gaps: Move to gaps list with question
    - fix_reference: Correct the cross-reference

    SCHEMA OUTPUT REQUIRED - Return ONLY valid JSON.

  expected_output: >
    Return a JSON object with these fields:

    verified_items: array of objects with fields id, type, status (supported or unsupported or ambiguous), context_id, confidence (number 0-1)

    issues: object containing these arrays:
    - unsupported: array of objects with fields item_id, type, section, reason
    - ambiguous: array of objects with fields item_id, type, section, interpretations array
    - inconsistent_with_requirements: array of objects with fields item_id, type, section, contradiction
    - extrapolations: array of objects with fields item_id, type, section, extrapolated_content
    - broken_references: array of objects with fields source_id, target_id, section
    - format_violations: array of objects with fields section, violation

    actions_recommended: array of objects with fields item_id, action, rationale, priority (high or medium or low)

    verification_summary: object with fields total_items_verified, supported, unsupported, ambiguous, extrapolations, grounding_score (all numbers)

validate_specification_compliance:
  description: >
    [Compliance Validation] Check specification against policies and standards.

    YOU RECEIVE:
    - draft_sections_json: {draft_sections_json}
    - verification_results_json: {verification_results_json}
    - target_audience: {target_audience}

    YOUR TASK: Verify compliance with all standards and policies.

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    COMPLIANCE CHECKS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    1. LANGUAGE COMPLIANCE:
       - Document in pt-BR (Portuguese - Brazil)
       - No first person (eu, nÃ³s, nosso, meu, nossa)
       - Technical terms consistent throughout
       - No informal language

    2. STYLE COMPLIANCE:
       - Professional tone
       - Clear and objective descriptions
       - No ambiguous terms without definition in glossary
       - Consistent terminology

    3. STRUCTURE COMPLIANCE:
       - All 14 sections present
       - Correct numbering (## 1., ## 2., ... ## 14.)
       - Subsections properly nested
       - Tables formatted correctly
       - Lists properly indented

    4. CONTENT POLICIES:
       - No sensitive data (PII) unauthorized
       - No security vulnerabilities documented in detail
       - Compliance with IEEE 830 structure
       - No confidential information exposed

    5. TRACEABILITY COMPLIANCE:
       - Every RF has context_id
       - Every UC references related FRs
       - Every RN references related FRs
       - Traceability matrix complete
       - No orphan references

    6. CONSISTENCY COMPLIANCE:
       - Versions referenced correctly
       - Dates consistent
       - IDs unique and sequential
       - Cross-references valid

    7. MINIMUM REQUIREMENTS:
       - At least 10 use cases
       - Each UC has minimum 5 steps in main flow
       - Each UC has minimum 2 alternative flows
       - Each UC has minimum 2 exception flows
       - Traceability matrix has all FRs mapped

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    VIOLATION SEVERITY
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - critical: Blocks approval (missing sections, security issues)
    - high: Must fix before delivery (first person, missing traceability)
    - medium: Should fix (formatting issues, inconsistent terms)
    - low: Nice to fix (minor style issues)

    SCHEMA OUTPUT REQUIRED - Return ONLY valid JSON.

  expected_output: >
    Return a JSON object with these fields:

    compliance_ok: boolean indicating overall compliance

    violations: array of violation objects with fields type (language or style or structure or policy or traceability or consistency or minimum_requirements), location (section or item ID), description, severity (critical or high or medium or low), current_value, expected_value

    checks_passed: object with boolean fields language, style, structure, policies, traceability, consistency, minimum_requirements

    compliance_score: number from 0 to 100

    corrections_needed: array of objects with fields location, current, corrected, reason

    minimum_requirements_check: object with fields use_cases_count, use_cases_with_min_steps, use_cases_with_alt_flows, use_cases_with_exc_flows (all numbers), and traceability_complete (boolean)

format_final_specification:
  description: >
    [Final Formatting] Generate final Markdown document with fallback.

    YOU RECEIVE:
    - draft_sections_json: {draft_sections_json}
    - verification_results_json: {verification_results_json}
    - compliance_results_json: {compliance_results_json}
    - project_name: {project_name}
    - requirements_version: {requirements_version}
    - requirements_created_at: {requirements_created_at}

    YOUR TASK: Produce the final formatted specification document.

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FORMATTING TASKS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    1. APPLY CORRECTIONS:
       - Fix all compliance violations from compliance_results_json
       - Remove or mark unsupported items from verification_results_json
       - Move extrapolations to gaps section
       - Fix broken references

    2. NORMALIZE STRUCTURE:
       - Consistent heading levels (## for sections, ### for subsections)
       - Sequential numbering (1., 2., 3., ...)
       - Tables properly aligned
       - Lists properly formatted
       - Code blocks for technical content

    3. ADD METADATA:
       - Document version
       - Generation date
       - Requirements reference
       - trace_id for audit trail

    4. GENERATE FINAL DOCUMENT:
       Start with header:
       ```markdown
       # EspecificaÃ§Ã£o Funcional - {project_name}

       **VersÃ£o:** 1.0
       **Data:** {requirements_created_at}
       **Baseado em:** Requisitos v{requirements_version}
       **Status:** [DETERMINAR: "complete" se grounding_score >= 70 e todas seÃ§Ãµes preenchidas, senÃ£o "partial"]
       **trace_id:** [GERAR: UUID v4 Ãºnico, ex: "550e8400-e29b-41d4-a716-446655440000"]

       ---
       ```

       Then include ALL 14 sections with content.

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FALLBACK HANDLING
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    IF grounding_score < 70:
    - Set status = "partial"
    - Add warning banner at top
    - List all unsupported items in gaps

    IF compliance_score < 80:
    - Add compliance warning section
    - List all violations

    IF sections are incomplete:
    - Generate placeholder with explicit warning:
      ```markdown
      ### X.Y [Section Name]

      âš ï¸ **SEÃ‡ÃƒO INCOMPLETA**

      Esta seÃ§Ã£o nÃ£o pÃ´de ser completamente gerada devido a:
      - [Motivo 1]
      - [Motivo 2]

      **Perguntas para Completar:**
      1. [Pergunta especÃ­fica 1]
      2. [Pergunta especÃ­fica 2]
      ```

    ALWAYS add section at end if there are gaps:
    ```markdown
    ## 15. LimitaÃ§Ãµes e PrÃ³ximos Passos

    ### 15.1 Gaps Identificados
    | # | SeÃ§Ã£o | DescriÃ§Ã£o | Pergunta |
    |---|-------|-----------|----------|
    | 1 | X | ... | ... |

    ### 15.2 InformaÃ§Ãµes NecessÃ¡rias
    [List of information needed to complete]

    ### 15.3 RecomendaÃ§Ãµes
    [Next steps to complete specification]
    ```

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    CRITICAL RULES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    - NEVER invent content - prefer partial with gaps
    - ALWAYS include all 14 base sections (even if incomplete)
    - ALWAYS generate traceability matrix
    - Document MUST be in pt-BR
    - NO first person language

    SCHEMA OUTPUT REQUIRED - Return ONLY valid JSON.

  expected_output: >
    Return a JSON object with these fields:

    status: one of complete, partial, or failed

    document_md: the complete Markdown document as a single string with all 14+ sections

    gaps: array of objects with fields section (number), title, missing, question

    warnings: array of objects with fields type, message

    corrections_applied: array of objects with fields location, original, corrected

    metadata: object with fields trace_id (string), generation_timestamp (string), requirements_version (number), grounding_score (number), compliance_score (number), total_sections (number), complete_sections (number), partial_sections (number), total_frs (number), total_ucs (number), total_rns (number), total_words (number)
